{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse der Tweets von Bundestagsabgeordneten\n",
    "\n",
    "Training auf Basis von TRAIN_FILENAME und Vergabe der Labels.\n",
    "Es wird itteriert über Wochen i Zeitraum Mai 2019 bis inkl. Juli 2020\n",
    "\n",
    "## 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, gensim, numpy as np\n",
    "import pandas as pd \n",
    "import pymongo\n",
    "import csv\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "db = client['Twitter']\n",
    "All_Tweets_collection = db['twitter_mdp_ex_date_proj']\n",
    "\n",
    "PICKLE_FOLDER_PATH = '/home/lisa/Darmstadt/Master Arbeit/06_Analyse/pickle_TU_Wien/'\n",
    "Eval_Path = '/home/lisa/Darmstadt/Master Arbeit/06_Analyse/Evaluierung/'\n",
    "Path = '/home/lisa/Darmstadt/Master Arbeit/06_Analyse/'\n",
    "\n",
    "\n",
    "# Bereits analysierte Tweets werden nicht erneut durchlaufen - lese Liste der pickle Files:\n",
    "with open(PICKLE_FOLDER_PATH + 'Twitter_pickle.txt') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        processed_weeks = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242894"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "# sample_df = pd.DataFrame(list(All_Tweets_collection.aggregate([ {\"$sample\": {\"size\": 50 }}], \n",
    "#                                      allowDiskUse=True\n",
    "#                                    )))\n",
    "\n",
    "time_sample_df = pd.DataFrame(list(All_Tweets_collection.find( {# 14.08.19, 06.11.19 fehlt \n",
    "            'created_at_datetime': {'$gte': datetime.datetime(2019,5,1,0,0,0), # 17.02. fehlt\n",
    "                                    '$lt': datetime.datetime(2020,8,1,0,0,0)},#22\n",
    "            'retweeted_id': None\n",
    "            })\n",
    "        ))# Load the regular expression library\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # https://www.compart.com/de/unicode/block/U+1F900\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "sample_df = time_sample_df\n",
    "# Remove punctuation\n",
    "sample_df.loc[:,('full_text_processed')] = sample_df.loc[:,('full_text')].map(lambda x: re.sub('[,\\.!?#@\\\\n\"“„\\:;&\\(\\)]', '', x))\n",
    "# Remove Links\n",
    "sample_df.loc[:,('full_text_processed')] = sample_df.loc[:,('full_text_processed')].map(lambda x: re.sub('http.*', '', x))\n",
    "\n",
    "sample_df.loc[:,('full_text_processed')] = sample_df.loc[:,('full_text_processed')].map(lambda x: re.sub('amp', '', x))\n",
    "# Convert the titles to lowercase\n",
    "#sample_df['full_text_processed'] = sample_df['full_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "#sample_df['full_text_processed'] = sample_df['full_text_processed'].map(lambda x: remove_emoji(x))\n",
    "# Print out the first rows of papers\n",
    "#sample_df['full_text_processed'].head(200)\n",
    "\n",
    "sample_df = sample_df[sample_df['full_text_processed'] != '']\n",
    "sample_df = sample_df[sample_df['full_text_processed'] != ' ']\n",
    "sample_df = sample_df[sample_df['full_text_processed'] != '  ']\n",
    "\n",
    "sample_df.loc[:,('Monat')] = sample_df.created_at_datetime.dt.strftime('%y-%m')\n",
    "sample_df.loc[:,('Woche')] = sample_df.created_at_datetime.dt.strftime('%y-w%U')\n",
    "len(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#sample_df[sample_df['Woche'] == '20-w07'].sort_values('created_at_datetime')['created_at_datetime']\n",
    "#print(sample_df['full_text_processed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "Code von TUWien angepasst für die Anwendung auf eigene Tweets (TUWienKBS at GermEval 2018 : German Abusive Tweet Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pickle, gensim, numpy as np\n",
    "\n",
    "from utilities import get_train_data, get_test_data, Tokenizer, find_subtoken\n",
    "\n",
    "#Test_TRAIN_FILENAME = Path + 'germEvalmore_train.txt' # Gelabelte Daten- random sample 3000 zum testen\n",
    "#TRAIN_FILENAME = Path + 'germeval2018.train_imp.txt' # ALLE gelabelten Daten\n",
    "TRAIN_FILENAME = Eval_Path + 'germeval2018.training_all_8541.txt' # Alle von GermEval gelabelten Daten\n",
    "#TRAIN_FILENAME = Eval_Path + 'self_label_train_1000_und_8541.txt' # Alle von GermEval gelabelten + 1000 selbst gelabelte\n",
    "\n",
    "#------------------------------\n",
    "#source:\n",
    "#http://www.cl.uni-heidelberg.de/english/research/downloads/resource_pages/GermanTwitterEmbeddings/GermanTwitterEmbeddings_data.shtml\n",
    "MODEL_FILENAME  = \"/home/lisa/Darmstadt/Master Arbeit/06_Analyse/twitter-de_d100_w5_min10.bin\" # 821,8 MB\n",
    "MODEL_DIMENSION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8541"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train_t1, y_train_t2 = get_train_data(TRAIN_FILENAME)\n",
    "len(X_train) #10343 # 7343 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utilities import get_train_data, get_test_data, Tokenizer, find_subtoken\n",
    "test_rand = get_train_data(Eval_Path + 'self_label_test_802.txt')\n",
    "print(len(test_rand[1]))\n",
    "train = {'Text': test_rand[0], 'Label': test_rand[1], 'other_label': test_rand[2]} \n",
    "df_test_rand = pd.DataFrame(train)\n",
    "#np.array(df_test_rand['Text'])\n",
    "\n",
    "######## 20-w07, 19-w32, 19-w44, extra testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_CNGR_mdp: (802, 286641)\n",
      "X_CNGR_train: (8541, 286641)\n",
      "X_TNGR_mdp: (802, 31082)\n",
      "X_TNGR_train: (8541, 31082)\n",
      "X_EMB_mdp: (802, 100)\n",
      "X_EMB_train: (8541, 100)\n",
      "X_TIMP_task1_mdp: (802, 5000)\n",
      "X_TIMP_task1_train: (8541, 5000)\n",
      "X_CIMP_task1_mdp: (802, 6400)\n",
      "X_CIMP_task1_train: (8541, 6400)\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[ 0.51321657  0.60198338  0.35097487 ... -0.0416928   0.04020016\n",
      "  -0.035798  ]\n",
      " [ 0.37136491  0.55409823  0.51642371 ... -0.01057631 -0.1064922\n",
      "  -0.02542487]\n",
      " [ 0.42756603  0.25808367  0.40140532 ... -0.12117179 -0.07554074\n",
      "  -0.07992783]\n",
      " ...\n",
      " [ 0.40381768  0.68656824  0.55551403 ...  0.00638522  0.08741061\n",
      "   0.02864218]\n",
      " [ 0.20871208  0.58225346  0.5254333  ... -0.05331408 -0.04771642\n",
      "   0.07319433]\n",
      " [ 0.46545498  0.72501504  0.44013603 ...  0.01042647 -0.0127348\n",
      "  -0.02542487]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "[[ 3.66580886e-01  6.97863735e-01  7.82714377e-01 ... -8.29838347e-02\n",
      "  -7.67481688e-03 -5.32745857e-02]\n",
      " [ 3.93140909e-01  4.87555296e-01  4.28519785e-01 ...  1.43825187e-02\n",
      "   5.77442988e-02 -2.81741613e-02]\n",
      " [ 2.97891905e-01  5.87285898e-01  4.83479366e-01 ...  1.24457587e-02\n",
      "  -7.82119305e-03 -2.54248678e-02]\n",
      " ...\n",
      " [ 3.14941949e-01  6.69926495e-01  4.57050665e-01 ...  5.42002237e-04\n",
      "   2.43473850e-02 -3.99211108e-02]\n",
      " [ 9.13311386e-01  6.86568236e-01  5.55514029e-01 ... -1.19004401e-01\n",
      "   2.15746167e-02 -5.06572507e-02]\n",
      " [ 9.13311386e-01  6.11000192e-01  5.65458160e-01 ... -1.65539026e-01\n",
      "  -1.55787842e-01 -5.79716052e-02]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[ 0.51321657  0.60198338  0.35097487 ... -0.0416928   0.04020016\n",
      "  -0.035798  ]\n",
      " [ 0.37136491  0.55409823  0.51642371 ... -0.01057631 -0.1064922\n",
      "  -0.02542487]\n",
      " [ 0.42756603  0.25808367  0.40140532 ... -0.12117179 -0.07554074\n",
      "  -0.07992783]\n",
      " ...\n",
      " [ 0.40381768  0.68656824  0.55551403 ...  0.00638522  0.08741061\n",
      "   0.02864218]\n",
      " [ 0.20871208  0.58225346  0.5254333  ... -0.05331408 -0.04771642\n",
      "   0.07319433]\n",
      " [ 0.46545498  0.72501504  0.44013603 ...  0.01042647 -0.0127348\n",
      "  -0.02542487]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[ 3.66580886e-01  6.97863735e-01  7.82714377e-01 ... -8.29838347e-02\n",
      "  -7.67481688e-03 -5.32745857e-02]\n",
      " [ 3.93140909e-01  4.87555296e-01  4.28519785e-01 ...  1.43825187e-02\n",
      "   5.77442988e-02 -2.81741613e-02]\n",
      " [ 2.97891905e-01  5.87285898e-01  4.83479366e-01 ...  1.24457587e-02\n",
      "  -7.82119305e-03 -2.54248678e-02]\n",
      " ...\n",
      " [ 3.14941949e-01  6.69926495e-01  4.57050665e-01 ...  5.42002237e-04\n",
      "   2.43473850e-02 -3.99211108e-02]\n",
      " [ 9.13311386e-01  6.86568236e-01  5.55514029e-01 ... -1.19004401e-01\n",
      "   2.15746167e-02 -5.06572507e-02]\n",
      " [ 9.13311386e-01  6.11000192e-01  5.65458160e-01 ... -1.65539026e-01\n",
      "  -1.55787842e-01 -5.79716052e-02]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[ 0.51321657  0.60198338  0.35097487 ... -0.0416928   0.04020016\n",
      "  -0.035798  ]\n",
      " [ 0.37136491  0.55409823  0.51642371 ... -0.01057631 -0.1064922\n",
      "  -0.02542487]\n",
      " [ 0.42756603  0.25808367  0.40140532 ... -0.12117179 -0.07554074\n",
      "  -0.07992783]\n",
      " ...\n",
      " [ 0.40381768  0.68656824  0.55551403 ...  0.00638522  0.08741061\n",
      "   0.02864218]\n",
      " [ 0.20871208  0.58225346  0.5254333  ... -0.05331408 -0.04771642\n",
      "   0.07319433]\n",
      " [ 0.46545498  0.72501504  0.44013603 ...  0.01042647 -0.0127348\n",
      "  -0.02542487]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[ 3.66580886e-01  6.97863735e-01  7.82714377e-01 ... -8.29838347e-02\n",
      "  -7.67481688e-03 -5.32745857e-02]\n",
      " [ 3.93140909e-01  4.87555296e-01  4.28519785e-01 ...  1.43825187e-02\n",
      "   5.77442988e-02 -2.81741613e-02]\n",
      " [ 2.97891905e-01  5.87285898e-01  4.83479366e-01 ...  1.24457587e-02\n",
      "  -7.82119305e-03 -2.54248678e-02]\n",
      " ...\n",
      " [ 3.14941949e-01  6.69926495e-01  4.57050665e-01 ...  5.42002237e-04\n",
      "   2.43473850e-02 -3.99211108e-02]\n",
      " [ 9.13311386e-01  6.86568236e-01  5.55514029e-01 ... -1.19004401e-01\n",
      "   2.15746167e-02 -5.06572507e-02]\n",
      " [ 9.13311386e-01  6.11000192e-01  5.65458160e-01 ... -1.65539026e-01\n",
      "  -1.55787842e-01 -5.79716052e-02]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 118064)\t0.06832140888518141\n",
      "  (0, 85771)\t0.07235548395633176\n",
      "  (0, 56560)\t0.07235548395633176\n",
      "  (0, 6845)\t0.07235548395633176\n",
      "  (0, 259821)\t0.07991781952198222\n",
      "  (0, 246494)\t0.07535857894903215\n",
      "  (0, 242057)\t0.07373131555349188\n",
      "  (0, 226599)\t0.06497718044864063\n",
      "  (0, 28501)\t0.07535857894903215\n",
      "  (0, 190313)\t0.07991781952198222\n",
      "  (0, 195588)\t0.071163684417131\n",
      "  (0, 148673)\t0.07735018838562135\n",
      "  (0, 275133)\t0.06832140888518141\n",
      "  (0, 109801)\t0.06832140888518141\n",
      "  (0, 119919)\t0.06392593875287204\n",
      "  (0, 13785)\t0.060643907352672506\n",
      "  (0, 231321)\t0.07991781952198222\n",
      "  (0, 266865)\t0.07535857894903215\n",
      "  (0, 26090)\t0.06555320214841232\n",
      "  (0, 215447)\t0.07535857894903215\n",
      "  (0, 285548)\t0.06392593875287204\n",
      "  (0, 115077)\t0.05679906704356107\n",
      "  (0, 13011)\t0.055747825347792476\n",
      "  (0, 181459)\t0.06832140888518141\n",
      "  (0, 145831)\t0.06754481158500153\n",
      "  :\t:\n",
      "  (8540, 23369)\t0.05670474985797117\n",
      "  (8540, 195402)\t0.05312049605707629\n",
      "  (8540, 97960)\t0.053853651462524396\n",
      "  (8540, 274342)\t0.051571636823327834\n",
      "  (8540, 237977)\t0.05629500465807332\n",
      "  (8540, 175576)\t0.05312049605707629\n",
      "  (8540, 175572)\t0.05244251923782887\n",
      "  (8540, 44409)\t0.05629500465807332\n",
      "  (8540, 249799)\t0.07080061446278979\n",
      "  (8540, 166048)\t0.05416446992273363\n",
      "  (8540, 44408)\t0.05629500465807332\n",
      "  (8540, 249798)\t0.07080061446278979\n",
      "  (8540, 166047)\t0.054007720891501444\n",
      "  (8540, 44407)\t0.05629500465807332\n",
      "  (8540, 249795)\t0.059367722160527235\n",
      "  (8540, 166046)\t0.054007720891501444\n",
      "  (8540, 249782)\t0.05355319556984793\n",
      "  (8540, 79808)\t0.05312049605707629\n",
      "  (8540, 79806)\t0.052707621941292554\n",
      "  (8540, 79805)\t0.052574095912135174\n",
      "  (8540, 127213)\t0.05830616225588788\n",
      "  (8540, 222148)\t0.06406608903022974\n",
      "  (8540, 127212)\t0.05830616225588788\n",
      "  (8540, 222147)\t0.06360379066616362\n",
      "  (8540, 127211)\t0.05465176925184273LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "  (0, 280912)\t0.06622249519600037\n",
      "  (0, 277704)\t0.06109615751832261\n",
      "  (0, 275722)\t0.06409487282579808\n",
      "  (0, 275721)\t0.0589685351481203\n",
      "  (0, 275029)\t0.06622249519600037\n",
      "  (0, 275027)\t0.05661333353118344\n",
      "  (0, 274305)\t0.04347485715239196\n",
      "  (0, 273462)\t0.06409487282579808\n",
      "  (0, 273461)\t0.054829761191917806\n",
      "  (0, 268234)\t0.054829761191917806\n",
      "  (0, 268233)\t0.042821867814246406\n",
      "  (0, 267419)\t0.04587285006678963\n",
      "  (0, 267418)\t0.04512516927471607\n",
      "  (0, 267417)\t0.0448460515480161\n",
      "  (0, 267026)\t0.05731822302579619\n",
      "  (0, 256569)\t0.05731822302579619\n",
      "  (0, 255406)\t0.04394458591119463\n",
      "  (0, 254037)\t0.06109615751832261\n",
      "  (0, 254028)\t0.04314115805658861\n",
      "  (0, 252560)\t0.06409487282579808\n",
      "  (0, 251738)\t0.05537784463007162\n",
      "  (0, 251737)\t0.054829761191917806\n",
      "  (0, 251736)\t0.05431950771832071\n",
      "  (0, 247830)\t0.06409487282579808\n",
      "  (0, 243658)\t0.046031904410831014\n",
      "  :\t:\n",
      "  (801, 17617)\t0.04485464583995255\n",
      "  (801, 17616)\t0.042892583751617835\n",
      "  (801, 16677)\t0.03890857439135519\n",
      "  (801, 15409)\t0.03783434558678772\n",
      "  (801, 14921)\t0.045677361536047165\n",
      "  (801, 12606)\t0.05202106872631554\n",
      "  (801, 12605)\t0.05202106872631554\n",
      "  (801, 12604)\t0.05089774631079505\n",
      "  (801, 11430)\t0.04994799074122533\n",
      "  (801, 11429)\t0.04994799074122533\n",
      "  (801, 11428)\t0.04994799074122533\n",
      "  (801, 11414)\t0.03834807765451711\n",
      "  (801, 10192)\t0.046133956728370604\n",
      "  (801, 10191)\t0.045677361536047165\n",
      "  (801, 10187)\t0.04235648790043873\n",
      "  (801, 10186)\t0.03576126760169751\n",
      "  (801, 9627)\t0.04235648790043873\n",
      "  (801, 9626)\t0.04235648790043873\n",
      "  (801, 8747)\t0.03783434558678772\n",
      "  (801, 8702)\t0.041863327523192446\n",
      "  (801, 8508)\t0.03576126760169751\n",
      "  (801, 8507)\t0.035502717124583166\n",
      "  (801, 6286)\t0.04994799074122533\n",
      "  (801, 6285)\t0.04994799074122533\n",
      "  (801, 6281)\t0.04662711710561689LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 118064)\t0.06832140888518141\n",
      "  (0, 85771)\t0.07235548395633176\n",
      "  (0, 56560)\t0.07235548395633176\n",
      "  (0, 6845)\t0.07235548395633176\n",
      "  (0, 259821)\t0.07991781952198222\n",
      "  (0, 246494)\t0.07535857894903215\n",
      "  (0, 242057)\t0.07373131555349188\n",
      "  (0, 226599)\t0.06497718044864063\n",
      "  (0, 28501)\t0.07535857894903215\n",
      "  (0, 190313)\t0.07991781952198222\n",
      "  (0, 195588)\t0.071163684417131\n",
      "  (0, 148673)\t0.07735018838562135\n",
      "  (0, 275133)\t0.06832140888518141\n",
      "  (0, 109801)\t0.06832140888518141\n",
      "  (0, 119919)\t0.06392593875287204\n",
      "  (0, 13785)\t0.060643907352672506\n",
      "  (0, 231321)\t0.07991781952198222\n",
      "  (0, 266865)\t0.07535857894903215\n",
      "  (0, 26090)\t0.06555320214841232\n",
      "  (0, 215447)\t0.07535857894903215\n",
      "  (0, 285548)\t0.06392593875287204\n",
      "  (0, 115077)\t0.05679906704356107\n",
      "  (0, 13011)\t0.055747825347792476\n",
      "  (0, 181459)\t0.06832140888518141\n",
      "  (0, 145831)\t0.06754481158500153\n",
      "  :\t:\n",
      "  (8540, 23369)\t0.05670474985797117\n",
      "  (8540, 195402)\t0.05312049605707629\n",
      "  (8540, 97960)\t0.053853651462524396\n",
      "  (8540, 274342)\t0.051571636823327834\n",
      "  (8540, 237977)\t0.05629500465807332\n",
      "  (8540, 175576)\t0.05312049605707629\n",
      "  (8540, 175572)\t0.05244251923782887\n",
      "  (8540, 44409)\t0.05629500465807332\n",
      "  (8540, 249799)\t0.07080061446278979\n",
      "  (8540, 166048)\t0.05416446992273363\n",
      "  (8540, 44408)\t0.05629500465807332\n",
      "  (8540, 249798)\t0.07080061446278979\n",
      "  (8540, 166047)\t0.054007720891501444\n",
      "  (8540, 44407)\t0.05629500465807332\n",
      "  (8540, 249795)\t0.059367722160527235\n",
      "  (8540, 166046)\t0.054007720891501444\n",
      "  (8540, 249782)\t0.05355319556984793\n",
      "  (8540, 79808)\t0.05312049605707629\n",
      "  (8540, 79806)\t0.052707621941292554\n",
      "  (8540, 79805)\t0.052574095912135174\n",
      "  (8540, 127213)\t0.05830616225588788\n",
      "  (8540, 222148)\t0.06406608903022974\n",
      "  (8540, 127212)\t0.05830616225588788\n",
      "  (8540, 222147)\t0.06360379066616362\n",
      "  (8540, 127211)\t0.05465176925184273ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 4855)\t0.06109615751832261\n",
      "  (0, 5027)\t0.06622249519600037\n",
      "  (0, 6932)\t0.0589685351481203\n",
      "  (0, 7563)\t0.04431755949071081\n",
      "  (0, 8117)\t0.044710346053503776\n",
      "  (0, 8118)\t0.054829761191917806\n",
      "  (0, 8720)\t0.04784476685549158\n",
      "  (0, 9689)\t0.042515793435146866\n",
      "  (0, 9800)\t0.06109615751832261\n",
      "  (0, 10052)\t0.04512516927471607\n",
      "  (0, 10186)\t0.042926773714238135\n",
      "  (0, 10187)\t0.05084348216296706\n",
      "  (0, 10188)\t0.05809744221084713\n",
      "  (0, 11208)\t0.04784476685549158\n",
      "  (0, 11209)\t0.05537784463007162\n",
      "  (0, 11212)\t0.0589685351481203\n",
      "  (0, 12617)\t0.051831045884442324\n",
      "  (0, 12618)\t0.052571237316943714\n",
      "  (0, 12619)\t0.0589685351481203\n",
      "  (0, 15832)\t0.044984293740185095\n",
      "  (0, 15849)\t0.05731822302579619\n",
      "  (0, 16427)\t0.05339383341194416\n",
      "  (0, 16428)\t0.05339383341194416\n",
      "  (0, 17122)\t0.052971104533169354\n",
      "  (0, 17123)\t0.05339383341194416\n",
      "  :\t:\n",
      "  (801, 271564)\t0.04525228158162355\n",
      "  (801, 271565)\t0.04525228158162355\n",
      "  (801, 271566)\t0.04912527504513071\n",
      "  (801, 274693)\t0.0353361876472739\n",
      "  (801, 274697)\t0.03567387300764823\n",
      "  (801, 274700)\t0.036123796606925856\n",
      "  (801, 274701)\t0.036123796606925856\n",
      "  (801, 275169)\t0.03724711902244634\n",
      "  (801, 275181)\t0.040981652376445396\n",
      "  (801, 275182)\t0.040981652376445396\n",
      "  (801, 280373)\t0.04140673233086901\n",
      "  (801, 280379)\t0.047750439521137375\n",
      "  (801, 280380)\t0.047750439521137375\n",
      "  (801, 282127)\t0.03478641539630425\n",
      "  (801, 282128)\t0.039689518974396536\n",
      "  (801, 282646)\t0.039365169583678625\n",
      "  (801, 282661)\t0.04716321295679599\n",
      "  (801, 282665)\t0.04994799074122533\n",
      "  (801, 282666)\t0.0551683755159732\n",
      "  (801, 283458)\t0.03567387300764823\n",
      "  (801, 283460)\t0.03584991971500329\n",
      "  (801, 283461)\t0.03584991971500329\n",
      "  (801, 283462)\t0.03584991971500329\n",
      "  (801, 283465)\t0.04448112447574099\n",
      "  (801, 285320)\t0.04210497479196588ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 118064)\t0.06832140888518141\n",
      "  (0, 85771)\t0.07235548395633176\n",
      "  (0, 56560)\t0.07235548395633176\n",
      "  (0, 6845)\t0.07235548395633176\n",
      "  (0, 259821)\t0.07991781952198222\n",
      "  (0, 246494)\t0.07535857894903215\n",
      "  (0, 242057)\t0.07373131555349188\n",
      "  (0, 226599)\t0.06497718044864063\n",
      "  (0, 28501)\t0.07535857894903215\n",
      "  (0, 190313)\t0.07991781952198222\n",
      "  (0, 195588)\t0.071163684417131\n",
      "  (0, 148673)\t0.07735018838562135\n",
      "  (0, 275133)\t0.06832140888518141\n",
      "  (0, 109801)\t0.06832140888518141\n",
      "  (0, 119919)\t0.06392593875287204\n",
      "  (0, 13785)\t0.060643907352672506\n",
      "  (0, 231321)\t0.07991781952198222\n",
      "  (0, 266865)\t0.07535857894903215\n",
      "  (0, 26090)\t0.06555320214841232\n",
      "  (0, 215447)\t0.07535857894903215\n",
      "  (0, 285548)\t0.06392593875287204\n",
      "  (0, 115077)\t0.05679906704356107\n",
      "  (0, 13011)\t0.055747825347792476\n",
      "  (0, 181459)\t0.06832140888518141\n",
      "  (0, 145831)\t0.06754481158500153\n",
      "  :\t:\n",
      "  (8540, 23369)\t0.05670474985797117\n",
      "  (8540, 195402)\t0.05312049605707629\n",
      "  (8540, 97960)\t0.053853651462524396\n",
      "  (8540, 274342)\t0.051571636823327834\n",
      "  (8540, 237977)\t0.05629500465807332\n",
      "  (8540, 175576)\t0.05312049605707629\n",
      "  (8540, 175572)\t0.05244251923782887\n",
      "  (8540, 44409)\t0.05629500465807332\n",
      "  (8540, 249799)\t0.07080061446278979\n",
      "  (8540, 166048)\t0.05416446992273363\n",
      "  (8540, 44408)\t0.05629500465807332\n",
      "  (8540, 249798)\t0.07080061446278979\n",
      "  (8540, 166047)\t0.054007720891501444\n",
      "  (8540, 44407)\t0.05629500465807332\n",
      "  (8540, 249795)\t0.059367722160527235\n",
      "  (8540, 166046)\t0.054007720891501444\n",
      "  (8540, 249782)\t0.05355319556984793\n",
      "  (8540, 79808)\t0.05312049605707629\n",
      "  (8540, 79806)\t0.052707621941292554\n",
      "  (8540, 79805)\t0.052574095912135174\n",
      "  (8540, 127213)\t0.05830616225588788\n",
      "  (8540, 222148)\t0.06406608903022974\n",
      "  (8540, 127212)\t0.05830616225588788\n",
      "  (8540, 222147)\t0.06360379066616362\n",
      "  (8540, 127211)\t0.05465176925184273ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 4855)\t0.06109615751832261\n",
      "  (0, 5027)\t0.06622249519600037\n",
      "  (0, 6932)\t0.0589685351481203\n",
      "  (0, 7563)\t0.04431755949071081\n",
      "  (0, 8117)\t0.044710346053503776\n",
      "  (0, 8118)\t0.054829761191917806\n",
      "  (0, 8720)\t0.04784476685549158\n",
      "  (0, 9689)\t0.042515793435146866\n",
      "  (0, 9800)\t0.06109615751832261\n",
      "  (0, 10052)\t0.04512516927471607\n",
      "  (0, 10186)\t0.042926773714238135\n",
      "  (0, 10187)\t0.05084348216296706\n",
      "  (0, 10188)\t0.05809744221084713\n",
      "  (0, 11208)\t0.04784476685549158\n",
      "  (0, 11209)\t0.05537784463007162\n",
      "  (0, 11212)\t0.0589685351481203\n",
      "  (0, 12617)\t0.051831045884442324\n",
      "  (0, 12618)\t0.052571237316943714\n",
      "  (0, 12619)\t0.0589685351481203\n",
      "  (0, 15832)\t0.044984293740185095\n",
      "  (0, 15849)\t0.05731822302579619\n",
      "  (0, 16427)\t0.05339383341194416\n",
      "  (0, 16428)\t0.05339383341194416\n",
      "  (0, 17122)\t0.052971104533169354\n",
      "  (0, 17123)\t0.05339383341194416\n",
      "  :\t:\n",
      "  (801, 271564)\t0.04525228158162355\n",
      "  (801, 271565)\t0.04525228158162355\n",
      "  (801, 271566)\t0.04912527504513071\n",
      "  (801, 274693)\t0.0353361876472739\n",
      "  (801, 274697)\t0.03567387300764823\n",
      "  (801, 274700)\t0.036123796606925856\n",
      "  (801, 274701)\t0.036123796606925856\n",
      "  (801, 275169)\t0.03724711902244634\n",
      "  (801, 275181)\t0.040981652376445396\n",
      "  (801, 275182)\t0.040981652376445396\n",
      "  (801, 280373)\t0.04140673233086901\n",
      "  (801, 280379)\t0.047750439521137375\n",
      "  (801, 280380)\t0.047750439521137375\n",
      "  (801, 282127)\t0.03478641539630425\n",
      "  (801, 282128)\t0.039689518974396536\n",
      "  (801, 282646)\t0.039365169583678625\n",
      "  (801, 282661)\t0.04716321295679599\n",
      "  (801, 282665)\t0.04994799074122533\n",
      "  (801, 282666)\t0.0551683755159732\n",
      "  (801, 283458)\t0.03567387300764823\n",
      "  (801, 283460)\t0.03584991971500329\n",
      "  (801, 283461)\t0.03584991971500329\n",
      "  (801, 283462)\t0.03584991971500329\n",
      "  (801, 283465)\t0.04448112447574099\n",
      "  (801, 285320)\t0.04210497479196588ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 27994)\t0.3838999798572487\n",
      "  (0, 167)\t0.3838999798572487\n",
      "  (0, 11815)\t0.2750439403096284\n",
      "  (0, 12577)\t0.37156589032095133\n",
      "  (0, 29225)\t0.3541819674903452\n",
      "  (0, 27993)\t0.336798044659739\n",
      "  (0, 12836)\t0.309530643789222\n",
      "  (0, 19704)\t0.309530643789222\n",
      "  (0, 12574)\t0.24705263226499857\n",
      "  (1, 820)\t0.2586172666205532\n",
      "  (1, 3661)\t0.2586172666205532\n",
      "  (1, 13449)\t0.243863381418298\n",
      "  (1, 29037)\t0.23028853460577484\n",
      "  (1, 5921)\t0.243863381418298\n",
      "  (1, 6299)\t0.2141254709135135\n",
      "  (1, 819)\t0.22688667435053542\n",
      "  (1, 26623)\t0.23859749185895449\n",
      "  (1, 1352)\t0.21626588921451245\n",
      "  (1, 22167)\t0.2010710423207007\n",
      "  (1, 3660)\t0.2586172666205532\n",
      "  (1, 16276)\t0.17976739264857394\n",
      "  (1, 13448)\t0.23028853460577484\n",
      "  (1, 23782)\t0.2010710423207007\n",
      "  (1, 17544)\t0.21026875984417612\n",
      "  (1, 22586)\t0.2586172666205532\n",
      "  :\t:\n",
      "  (8539, 15326)\t0.3597472849220919\n",
      "  (8539, 16148)\t0.3333514554024809\n",
      "  (8539, 13153)\t0.37740436408938804\n",
      "  (8539, 13152)\t0.3472193878806087\n",
      "  (8539, 7139)\t0.3198449168281999\n",
      "  (8539, 13148)\t0.2527620544635877\n",
      "  (8539, 28108)\t0.27298150298492224\n",
      "  (8540, 15670)\t0.26420752111345863\n",
      "  (8540, 15669)\t0.25571895796534816\n",
      "  (8540, 23775)\t0.26420752111345863\n",
      "  (8540, 19362)\t0.26420752111345863\n",
      "  (8540, 6854)\t0.26420752111345863\n",
      "  (8540, 21079)\t0.24913471686098887\n",
      "  (8540, 28661)\t0.25571895796534816\n",
      "  (8540, 28660)\t0.24375500016568905\n",
      "  (8540, 12102)\t0.2082296749654496\n",
      "  (8540, 15690)\t0.19529819604333695\n",
      "  (8540, 24022)\t0.21671823811356009\n",
      "  (8540, 19359)\t0.2041057541960977\n",
      "  (8540, 28721)\t0.20541738126556194\n",
      "  (8540, 17321)\t0.1962657171657905\n",
      "  (8540, 16322)\t0.22868219591321923\n",
      "  (8540, 28521)\t0.26420752111345863\n",
      "  (8540, 23774)\t0.24913471686098887\n",
      "  (8540, 28516)\t0.183018655015703LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "  (0, 31012)\t0.19629602813319552\n",
      "  (0, 29339)\t0.17777813051935185\n",
      "  (0, 24499)\t0.21017981802632119\n",
      "  (0, 22562)\t0.18007468395740253\n",
      "  (0, 21087)\t0.19764751506211392\n",
      "  (0, 20864)\t0.20288964725449063\n",
      "  (0, 18754)\t0.28433999818661776\n",
      "  (0, 18150)\t0.25743392775219864\n",
      "  (0, 18144)\t0.28433999818661776\n",
      "  (0, 17590)\t0.24945340044929512\n",
      "  (0, 16637)\t0.22744240793593953\n",
      "  (0, 11370)\t0.24945340044929512\n",
      "  (0, 10183)\t0.25743392775219864\n",
      "  (0, 9006)\t0.24945340044929512\n",
      "  (0, 8896)\t0.22925748192656017\n",
      "  (0, 7855)\t0.17968020497464973\n",
      "  (0, 6261)\t0.2531936183838738\n",
      "  (0, 5462)\t0.23542293523884308\n",
      "  (0, 5077)\t0.18974378380569382\n",
      "  (1, 29553)\t0.2658389200236334\n",
      "  (1, 21441)\t0.3626991640001594\n",
      "  (1, 21436)\t0.26966517287340536\n",
      "  (1, 14323)\t0.311466067756722\n",
      "  (1, 13105)\t0.33858451847566556\n",
      "  (1, 11120)\t0.2894327227328889\n",
      "  :\t:\n",
      "  (800, 11859)\t0.21793303782177145\n",
      "  (800, 10090)\t0.3006207077206833\n",
      "  (800, 9331)\t0.27969280266254987\n",
      "  (800, 1942)\t0.27594148436932153\n",
      "  (801, 30265)\t0.21631981695297126\n",
      "  (801, 29054)\t0.1885965321210265\n",
      "  (801, 28744)\t0.24189499299482195\n",
      "  (801, 28741)\t0.1682345777558774\n",
      "  (801, 27283)\t0.22627519919534358\n",
      "  (801, 27186)\t0.24992467112109729\n",
      "  (801, 25255)\t0.17372508445815196\n",
      "  (801, 24777)\t0.21631981695297126\n",
      "  (801, 23291)\t0.24992467112109729\n",
      "  (801, 18165)\t0.24992467112109729\n",
      "  (801, 16232)\t0.24992467112109729\n",
      "  (801, 16231)\t0.22627519919534358\n",
      "  (801, 11736)\t0.19074464091112056\n",
      "  (801, 10650)\t0.24189499299482195\n",
      "  (801, 10312)\t0.19697294313981586\n",
      "  (801, 9011)\t0.21365955363011704\n",
      "  (801, 7632)\t0.19188404968163117\n",
      "  (801, 5183)\t0.24992467112109729\n",
      "  (801, 5179)\t0.16161035911725982\n",
      "  (801, 3887)\t0.22627519919534358\n",
      "  (801, 3577)\t0.21365955363011704LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 27994)\t0.3838999798572487\n",
      "  (0, 167)\t0.3838999798572487\n",
      "  (0, 11815)\t0.2750439403096284\n",
      "  (0, 12577)\t0.37156589032095133\n",
      "  (0, 29225)\t0.3541819674903452\n",
      "  (0, 27993)\t0.336798044659739\n",
      "  (0, 12836)\t0.309530643789222\n",
      "  (0, 19704)\t0.309530643789222\n",
      "  (0, 12574)\t0.24705263226499857\n",
      "  (1, 820)\t0.2586172666205532\n",
      "  (1, 3661)\t0.2586172666205532\n",
      "  (1, 13449)\t0.243863381418298\n",
      "  (1, 29037)\t0.23028853460577484\n",
      "  (1, 5921)\t0.243863381418298\n",
      "  (1, 6299)\t0.2141254709135135\n",
      "  (1, 819)\t0.22688667435053542\n",
      "  (1, 26623)\t0.23859749185895449\n",
      "  (1, 1352)\t0.21626588921451245\n",
      "  (1, 22167)\t0.2010710423207007\n",
      "  (1, 3660)\t0.2586172666205532\n",
      "  (1, 16276)\t0.17976739264857394\n",
      "  (1, 13448)\t0.23028853460577484\n",
      "  (1, 23782)\t0.2010710423207007\n",
      "  (1, 17544)\t0.21026875984417612\n",
      "  (1, 22586)\t0.2586172666205532\n",
      "  :\t:\n",
      "  (8539, 15326)\t0.3597472849220919\n",
      "  (8539, 16148)\t0.3333514554024809\n",
      "  (8539, 13153)\t0.37740436408938804\n",
      "  (8539, 13152)\t0.3472193878806087\n",
      "  (8539, 7139)\t0.3198449168281999\n",
      "  (8539, 13148)\t0.2527620544635877\n",
      "  (8539, 28108)\t0.27298150298492224\n",
      "  (8540, 15670)\t0.26420752111345863\n",
      "  (8540, 15669)\t0.25571895796534816\n",
      "  (8540, 23775)\t0.26420752111345863\n",
      "  (8540, 19362)\t0.26420752111345863\n",
      "  (8540, 6854)\t0.26420752111345863\n",
      "  (8540, 21079)\t0.24913471686098887\n",
      "  (8540, 28661)\t0.25571895796534816\n",
      "  (8540, 28660)\t0.24375500016568905\n",
      "  (8540, 12102)\t0.2082296749654496\n",
      "  (8540, 15690)\t0.19529819604333695\n",
      "  (8540, 24022)\t0.21671823811356009\n",
      "  (8540, 19359)\t0.2041057541960977\n",
      "  (8540, 28721)\t0.20541738126556194\n",
      "  (8540, 17321)\t0.1962657171657905\n",
      "  (8540, 16322)\t0.22868219591321923\n",
      "  (8540, 28521)\t0.26420752111345863\n",
      "  (8540, 23774)\t0.24913471686098887\n",
      "  (8540, 28516)\t0.183018655015703ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 5077)\t0.18974378380569382\n",
      "  (0, 5462)\t0.23542293523884308\n",
      "  (0, 6261)\t0.2531936183838738\n",
      "  (0, 7855)\t0.17968020497464973\n",
      "  (0, 8896)\t0.22925748192656017\n",
      "  (0, 9006)\t0.24945340044929512\n",
      "  (0, 10183)\t0.25743392775219864\n",
      "  (0, 11370)\t0.24945340044929512\n",
      "  (0, 16637)\t0.22744240793593953\n",
      "  (0, 17590)\t0.24945340044929512\n",
      "  (0, 18144)\t0.28433999818661776\n",
      "  (0, 18150)\t0.25743392775219864\n",
      "  (0, 18754)\t0.28433999818661776\n",
      "  (0, 20864)\t0.20288964725449063\n",
      "  (0, 21087)\t0.19764751506211392\n",
      "  (0, 22562)\t0.18007468395740253\n",
      "  (0, 24499)\t0.21017981802632119\n",
      "  (0, 29339)\t0.17777813051935185\n",
      "  (0, 31012)\t0.19629602813319552\n",
      "  (1, 7304)\t0.36959584885125024\n",
      "  (1, 7567)\t0.3777528957107077\n",
      "  (1, 8600)\t0.3877363142184422\n",
      "  (1, 11120)\t0.2894327227328889\n",
      "  (1, 13105)\t0.33858451847566556\n",
      "  (1, 14323)\t0.311466067756722\n",
      "  :\t:\n",
      "  (800, 24666)\t0.2838864197261251\n",
      "  (800, 25901)\t0.31880844622137994\n",
      "  (800, 30924)\t0.3006207077206833\n",
      "  (800, 31069)\t0.3085656430774868\n",
      "  (801, 3577)\t0.21365955363011704\n",
      "  (801, 3887)\t0.22627519919534358\n",
      "  (801, 5179)\t0.16161035911725982\n",
      "  (801, 5183)\t0.24992467112109729\n",
      "  (801, 7632)\t0.19188404968163117\n",
      "  (801, 9011)\t0.21365955363011704\n",
      "  (801, 10312)\t0.19697294313981586\n",
      "  (801, 10650)\t0.24189499299482195\n",
      "  (801, 11736)\t0.19074464091112056\n",
      "  (801, 16231)\t0.22627519919534358\n",
      "  (801, 16232)\t0.24992467112109729\n",
      "  (801, 18165)\t0.24992467112109729\n",
      "  (801, 23291)\t0.24992467112109729\n",
      "  (801, 24777)\t0.21631981695297126\n",
      "  (801, 25255)\t0.17372508445815196\n",
      "  (801, 27186)\t0.24992467112109729\n",
      "  (801, 27283)\t0.22627519919534358\n",
      "  (801, 28741)\t0.1682345777558774\n",
      "  (801, 28744)\t0.24189499299482195\n",
      "  (801, 29054)\t0.1885965321210265\n",
      "  (801, 30265)\t0.21631981695297126ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 27994)\t0.3838999798572487\n",
      "  (0, 167)\t0.3838999798572487\n",
      "  (0, 11815)\t0.2750439403096284\n",
      "  (0, 12577)\t0.37156589032095133\n",
      "  (0, 29225)\t0.3541819674903452\n",
      "  (0, 27993)\t0.336798044659739\n",
      "  (0, 12836)\t0.309530643789222\n",
      "  (0, 19704)\t0.309530643789222\n",
      "  (0, 12574)\t0.24705263226499857\n",
      "  (1, 820)\t0.2586172666205532\n",
      "  (1, 3661)\t0.2586172666205532\n",
      "  (1, 13449)\t0.243863381418298\n",
      "  (1, 29037)\t0.23028853460577484\n",
      "  (1, 5921)\t0.243863381418298\n",
      "  (1, 6299)\t0.2141254709135135\n",
      "  (1, 819)\t0.22688667435053542\n",
      "  (1, 26623)\t0.23859749185895449\n",
      "  (1, 1352)\t0.21626588921451245\n",
      "  (1, 22167)\t0.2010710423207007\n",
      "  (1, 3660)\t0.2586172666205532\n",
      "  (1, 16276)\t0.17976739264857394\n",
      "  (1, 13448)\t0.23028853460577484\n",
      "  (1, 23782)\t0.2010710423207007\n",
      "  (1, 17544)\t0.21026875984417612\n",
      "  (1, 22586)\t0.2586172666205532\n",
      "  :\t:\n",
      "  (8539, 15326)\t0.3597472849220919\n",
      "  (8539, 16148)\t0.3333514554024809\n",
      "  (8539, 13153)\t0.37740436408938804\n",
      "  (8539, 13152)\t0.3472193878806087\n",
      "  (8539, 7139)\t0.3198449168281999\n",
      "  (8539, 13148)\t0.2527620544635877\n",
      "  (8539, 28108)\t0.27298150298492224\n",
      "  (8540, 15670)\t0.26420752111345863\n",
      "  (8540, 15669)\t0.25571895796534816\n",
      "  (8540, 23775)\t0.26420752111345863\n",
      "  (8540, 19362)\t0.26420752111345863\n",
      "  (8540, 6854)\t0.26420752111345863\n",
      "  (8540, 21079)\t0.24913471686098887\n",
      "  (8540, 28661)\t0.25571895796534816\n",
      "  (8540, 28660)\t0.24375500016568905\n",
      "  (8540, 12102)\t0.2082296749654496\n",
      "  (8540, 15690)\t0.19529819604333695\n",
      "  (8540, 24022)\t0.21671823811356009\n",
      "  (8540, 19359)\t0.2041057541960977\n",
      "  (8540, 28721)\t0.20541738126556194\n",
      "  (8540, 17321)\t0.1962657171657905\n",
      "  (8540, 16322)\t0.22868219591321923\n",
      "  (8540, 28521)\t0.26420752111345863\n",
      "  (8540, 23774)\t0.24913471686098887\n",
      "  (8540, 28516)\t0.183018655015703ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 5077)\t0.18974378380569382\n",
      "  (0, 5462)\t0.23542293523884308\n",
      "  (0, 6261)\t0.2531936183838738\n",
      "  (0, 7855)\t0.17968020497464973\n",
      "  (0, 8896)\t0.22925748192656017\n",
      "  (0, 9006)\t0.24945340044929512\n",
      "  (0, 10183)\t0.25743392775219864\n",
      "  (0, 11370)\t0.24945340044929512\n",
      "  (0, 16637)\t0.22744240793593953\n",
      "  (0, 17590)\t0.24945340044929512\n",
      "  (0, 18144)\t0.28433999818661776\n",
      "  (0, 18150)\t0.25743392775219864\n",
      "  (0, 18754)\t0.28433999818661776\n",
      "  (0, 20864)\t0.20288964725449063\n",
      "  (0, 21087)\t0.19764751506211392\n",
      "  (0, 22562)\t0.18007468395740253\n",
      "  (0, 24499)\t0.21017981802632119\n",
      "  (0, 29339)\t0.17777813051935185\n",
      "  (0, 31012)\t0.19629602813319552\n",
      "  (1, 7304)\t0.36959584885125024\n",
      "  (1, 7567)\t0.3777528957107077\n",
      "  (1, 8600)\t0.3877363142184422\n",
      "  (1, 11120)\t0.2894327227328889\n",
      "  (1, 13105)\t0.33858451847566556\n",
      "  (1, 14323)\t0.311466067756722\n",
      "  :\t:\n",
      "  (800, 24666)\t0.2838864197261251\n",
      "  (800, 25901)\t0.31880844622137994\n",
      "  (800, 30924)\t0.3006207077206833\n",
      "  (800, 31069)\t0.3085656430774868\n",
      "  (801, 3577)\t0.21365955363011704\n",
      "  (801, 3887)\t0.22627519919534358\n",
      "  (801, 5179)\t0.16161035911725982\n",
      "  (801, 5183)\t0.24992467112109729\n",
      "  (801, 7632)\t0.19188404968163117\n",
      "  (801, 9011)\t0.21365955363011704\n",
      "  (801, 10312)\t0.19697294313981586\n",
      "  (801, 10650)\t0.24189499299482195\n",
      "  (801, 11736)\t0.19074464091112056\n",
      "  (801, 16231)\t0.22627519919534358\n",
      "  (801, 16232)\t0.24992467112109729\n",
      "  (801, 18165)\t0.24992467112109729\n",
      "  (801, 23291)\t0.24992467112109729\n",
      "  (801, 24777)\t0.21631981695297126\n",
      "  (801, 25255)\t0.17372508445815196\n",
      "  (801, 27186)\t0.24992467112109729\n",
      "  (801, 27283)\t0.22627519919534358\n",
      "  (801, 28741)\t0.1682345777558774\n",
      "  (801, 28744)\t0.24189499299482195\n",
      "  (801, 29054)\t0.1885965321210265\n",
      "  (801, 30265)\t0.21631981695297126ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[-0.11466956 -0.01908347  0.00172211 ...  0.06156928  0.08135319\n",
      "  -0.07859743]\n",
      " [-0.12918881 -0.02765546  0.11615171 ... -0.00593668 -0.0802549\n",
      "  -0.00568726]\n",
      " [-0.04746682 -0.10253195 -0.02464943 ...  0.13990997 -0.00122685\n",
      "   0.00821853]\n",
      " ...\n",
      " [-0.08659905 -0.00710907  0.0022457  ...  0.01209016  0.03789412\n",
      "  -0.08774336]\n",
      " [-0.17021359  0.03429338 -0.02271174 ...  0.0431119  -0.16762087\n",
      "  -0.16246864]\n",
      " [-0.06326013 -0.02837186  0.08405035 ... -0.06740867 -0.03769415\n",
      "  -0.08349329]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "[[-0.16421218 -0.00073272  0.04691822 ... -0.01254562 -0.07327801\n",
      "  -0.10237613]\n",
      " [-0.11650738  0.07978699  0.0179863  ...  0.04880052  0.00380368\n",
      "  -0.0271589 ]\n",
      " [-0.11894281  0.04145353  0.0978137  ... -0.02193728 -0.11535163\n",
      "  -0.0523463 ]\n",
      " ...\n",
      " [-0.06988689 -0.06927601  0.05345311 ... -0.09653039 -0.05638778\n",
      "  -0.02115867]\n",
      " [-0.15832969 -0.09984014 -0.06836596 ... -0.004405   -0.06729489\n",
      "   0.05255853]\n",
      " [-0.10925703  0.03403725  0.02126907 ...  0.00416451 -0.03184644\n",
      "  -0.03990714]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[-0.11466956 -0.01908347  0.00172211 ...  0.06156928  0.08135319\n",
      "  -0.07859743]\n",
      " [-0.12918881 -0.02765546  0.11615171 ... -0.00593668 -0.0802549\n",
      "  -0.00568726]\n",
      " [-0.04746682 -0.10253195 -0.02464943 ...  0.13990997 -0.00122685\n",
      "   0.00821853]\n",
      " ...\n",
      " [-0.08659905 -0.00710907  0.0022457  ...  0.01209016  0.03789412\n",
      "  -0.08774336]\n",
      " [-0.17021359  0.03429338 -0.02271174 ...  0.0431119  -0.16762087\n",
      "  -0.16246864]\n",
      " [-0.06326013 -0.02837186  0.08405035 ... -0.06740867 -0.03769415\n",
      "  -0.08349329]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[-0.16421218 -0.00073272  0.04691822 ... -0.01254562 -0.07327801\n",
      "  -0.10237613]\n",
      " [-0.11650738  0.07978699  0.0179863  ...  0.04880052  0.00380368\n",
      "  -0.0271589 ]\n",
      " [-0.11894281  0.04145353  0.0978137  ... -0.02193728 -0.11535163\n",
      "  -0.0523463 ]\n",
      " ...\n",
      " [-0.06988689 -0.06927601  0.05345311 ... -0.09653039 -0.05638778\n",
      "  -0.02115867]\n",
      " [-0.15832969 -0.09984014 -0.06836596 ... -0.004405   -0.06729489\n",
      "   0.05255853]\n",
      " [-0.10925703  0.03403725  0.02126907 ...  0.00416451 -0.03184644\n",
      "  -0.03990714]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[-0.11466956 -0.01908347  0.00172211 ...  0.06156928  0.08135319\n",
      "  -0.07859743]\n",
      " [-0.12918881 -0.02765546  0.11615171 ... -0.00593668 -0.0802549\n",
      "  -0.00568726]\n",
      " [-0.04746682 -0.10253195 -0.02464943 ...  0.13990997 -0.00122685\n",
      "   0.00821853]\n",
      " ...\n",
      " [-0.08659905 -0.00710907  0.0022457  ...  0.01209016  0.03789412\n",
      "  -0.08774336]\n",
      " [-0.17021359  0.03429338 -0.02271174 ...  0.0431119  -0.16762087\n",
      "  -0.16246864]\n",
      " [-0.06326013 -0.02837186  0.08405035 ... -0.06740867 -0.03769415\n",
      "  -0.08349329]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[-0.16421218 -0.00073272  0.04691822 ... -0.01254562 -0.07327801\n",
      "  -0.10237613]\n",
      " [-0.11650738  0.07978699  0.0179863  ...  0.04880052  0.00380368\n",
      "  -0.0271589 ]\n",
      " [-0.11894281  0.04145353  0.0978137  ... -0.02193728 -0.11535163\n",
      "  -0.0523463 ]\n",
      " ...\n",
      " [-0.06988689 -0.06927601  0.05345311 ... -0.09653039 -0.05638778\n",
      "  -0.02115867]\n",
      " [-0.15832969 -0.09984014 -0.06836596 ... -0.004405   -0.06729489\n",
      "   0.05255853]\n",
      " [-0.10925703  0.03403725  0.02126907 ...  0.00416451 -0.03184644\n",
      "  -0.03990714]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "train: (8541, 30)\n",
      "mdp: (802, 30)\n",
      "X_CNGR_mdp: (802, 286641)\n",
      "X_CNGR_train: (8541, 286641)\n",
      "X_TNGR_mdp: (802, 31082)\n",
      "X_TNGR_train: (8541, 31082)\n",
      "X_EMB_mdp: (802, 100)\n",
      "X_EMB_train: (8541, 100)\n",
      "X_TIMP_task1_mdp: (802, 5000)\n",
      "X_TIMP_task1_train: (8541, 5000)\n",
      "X_CIMP_task1_mdp: (802, 6400)\n",
      "X_CIMP_task1_train: (8541, 6400)\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[ 0.51321657  0.60198338  0.35097487 ... -0.0416928   0.04020016\n",
      "  -0.035798  ]\n",
      " [ 0.37136491  0.55409823  0.51642371 ... -0.01057631 -0.1064922\n",
      "  -0.02542487]\n",
      " [ 0.42756603  0.25808367  0.40140532 ... -0.12117179 -0.07554074\n",
      "  -0.07992783]\n",
      " ...\n",
      " [ 0.40381768  0.68656824  0.55551403 ...  0.00638522  0.08741061\n",
      "   0.02864218]\n",
      " [ 0.20871208  0.58225346  0.5254333  ... -0.05331408 -0.04771642\n",
      "   0.07319433]\n",
      " [ 0.46545498  0.72501504  0.44013603 ...  0.01042647 -0.0127348\n",
      "  -0.02542487]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "[[ 3.66580886e-01  6.97863735e-01  7.82714377e-01 ... -8.29838347e-02\n",
      "  -7.67481688e-03 -5.32745857e-02]\n",
      " [ 3.93140909e-01  4.87555296e-01  4.28519785e-01 ...  1.43825187e-02\n",
      "   5.77442988e-02 -2.81741613e-02]\n",
      " [ 2.97891905e-01  5.87285898e-01  4.83479366e-01 ...  1.24457587e-02\n",
      "  -7.82119305e-03 -2.54248678e-02]\n",
      " ...\n",
      " [ 3.14941949e-01  6.69926495e-01  4.57050665e-01 ...  5.42002237e-04\n",
      "   2.43473850e-02 -3.99211108e-02]\n",
      " [ 9.13311386e-01  6.86568236e-01  5.55514029e-01 ... -1.19004401e-01\n",
      "   2.15746167e-02 -5.06572507e-02]\n",
      " [ 9.13311386e-01  6.11000192e-01  5.65458160e-01 ... -1.65539026e-01\n",
      "  -1.55787842e-01 -5.79716052e-02]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[ 0.51321657  0.60198338  0.35097487 ... -0.0416928   0.04020016\n",
      "  -0.035798  ]\n",
      " [ 0.37136491  0.55409823  0.51642371 ... -0.01057631 -0.1064922\n",
      "  -0.02542487]\n",
      " [ 0.42756603  0.25808367  0.40140532 ... -0.12117179 -0.07554074\n",
      "  -0.07992783]\n",
      " ...\n",
      " [ 0.40381768  0.68656824  0.55551403 ...  0.00638522  0.08741061\n",
      "   0.02864218]\n",
      " [ 0.20871208  0.58225346  0.5254333  ... -0.05331408 -0.04771642\n",
      "   0.07319433]\n",
      " [ 0.46545498  0.72501504  0.44013603 ...  0.01042647 -0.0127348\n",
      "  -0.02542487]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[ 3.66580886e-01  6.97863735e-01  7.82714377e-01 ... -8.29838347e-02\n",
      "  -7.67481688e-03 -5.32745857e-02]\n",
      " [ 3.93140909e-01  4.87555296e-01  4.28519785e-01 ...  1.43825187e-02\n",
      "   5.77442988e-02 -2.81741613e-02]\n",
      " [ 2.97891905e-01  5.87285898e-01  4.83479366e-01 ...  1.24457587e-02\n",
      "  -7.82119305e-03 -2.54248678e-02]\n",
      " ...\n",
      " [ 3.14941949e-01  6.69926495e-01  4.57050665e-01 ...  5.42002237e-04\n",
      "   2.43473850e-02 -3.99211108e-02]\n",
      " [ 9.13311386e-01  6.86568236e-01  5.55514029e-01 ... -1.19004401e-01\n",
      "   2.15746167e-02 -5.06572507e-02]\n",
      " [ 9.13311386e-01  6.11000192e-01  5.65458160e-01 ... -1.65539026e-01\n",
      "  -1.55787842e-01 -5.79716052e-02]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[ 0.51321657  0.60198338  0.35097487 ... -0.0416928   0.04020016\n",
      "  -0.035798  ]\n",
      " [ 0.37136491  0.55409823  0.51642371 ... -0.01057631 -0.1064922\n",
      "  -0.02542487]\n",
      " [ 0.42756603  0.25808367  0.40140532 ... -0.12117179 -0.07554074\n",
      "  -0.07992783]\n",
      " ...\n",
      " [ 0.40381768  0.68656824  0.55551403 ...  0.00638522  0.08741061\n",
      "   0.02864218]\n",
      " [ 0.20871208  0.58225346  0.5254333  ... -0.05331408 -0.04771642\n",
      "   0.07319433]\n",
      " [ 0.46545498  0.72501504  0.44013603 ...  0.01042647 -0.0127348\n",
      "  -0.02542487]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[ 3.66580886e-01  6.97863735e-01  7.82714377e-01 ... -8.29838347e-02\n",
      "  -7.67481688e-03 -5.32745857e-02]\n",
      " [ 3.93140909e-01  4.87555296e-01  4.28519785e-01 ...  1.43825187e-02\n",
      "   5.77442988e-02 -2.81741613e-02]\n",
      " [ 2.97891905e-01  5.87285898e-01  4.83479366e-01 ...  1.24457587e-02\n",
      "  -7.82119305e-03 -2.54248678e-02]\n",
      " ...\n",
      " [ 3.14941949e-01  6.69926495e-01  4.57050665e-01 ...  5.42002237e-04\n",
      "   2.43473850e-02 -3.99211108e-02]\n",
      " [ 9.13311386e-01  6.86568236e-01  5.55514029e-01 ... -1.19004401e-01\n",
      "   2.15746167e-02 -5.06572507e-02]\n",
      " [ 9.13311386e-01  6.11000192e-01  5.65458160e-01 ... -1.65539026e-01\n",
      "  -1.55787842e-01 -5.79716052e-02]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 118064)\t0.06832140888518141\n",
      "  (0, 85771)\t0.07235548395633176\n",
      "  (0, 56560)\t0.07235548395633176\n",
      "  (0, 6845)\t0.07235548395633176\n",
      "  (0, 259821)\t0.07991781952198222\n",
      "  (0, 246494)\t0.07535857894903215\n",
      "  (0, 242057)\t0.07373131555349188\n",
      "  (0, 226599)\t0.06497718044864063\n",
      "  (0, 28501)\t0.07535857894903215\n",
      "  (0, 190313)\t0.07991781952198222\n",
      "  (0, 195588)\t0.071163684417131\n",
      "  (0, 148673)\t0.07735018838562135\n",
      "  (0, 275133)\t0.06832140888518141\n",
      "  (0, 109801)\t0.06832140888518141\n",
      "  (0, 119919)\t0.06392593875287204\n",
      "  (0, 13785)\t0.060643907352672506\n",
      "  (0, 231321)\t0.07991781952198222\n",
      "  (0, 266865)\t0.07535857894903215\n",
      "  (0, 26090)\t0.06555320214841232\n",
      "  (0, 215447)\t0.07535857894903215\n",
      "  (0, 285548)\t0.06392593875287204\n",
      "  (0, 115077)\t0.05679906704356107\n",
      "  (0, 13011)\t0.055747825347792476\n",
      "  (0, 181459)\t0.06832140888518141\n",
      "  (0, 145831)\t0.06754481158500153\n",
      "  :\t:\n",
      "  (8540, 23369)\t0.05670474985797117\n",
      "  (8540, 195402)\t0.05312049605707629\n",
      "  (8540, 97960)\t0.053853651462524396\n",
      "  (8540, 274342)\t0.051571636823327834\n",
      "  (8540, 237977)\t0.05629500465807332\n",
      "  (8540, 175576)\t0.05312049605707629\n",
      "  (8540, 175572)\t0.05244251923782887\n",
      "  (8540, 44409)\t0.05629500465807332\n",
      "  (8540, 249799)\t0.07080061446278979\n",
      "  (8540, 166048)\t0.05416446992273363\n",
      "  (8540, 44408)\t0.05629500465807332\n",
      "  (8540, 249798)\t0.07080061446278979\n",
      "  (8540, 166047)\t0.054007720891501444\n",
      "  (8540, 44407)\t0.05629500465807332\n",
      "  (8540, 249795)\t0.059367722160527235\n",
      "  (8540, 166046)\t0.054007720891501444\n",
      "  (8540, 249782)\t0.05355319556984793\n",
      "  (8540, 79808)\t0.05312049605707629\n",
      "  (8540, 79806)\t0.052707621941292554\n",
      "  (8540, 79805)\t0.052574095912135174\n",
      "  (8540, 127213)\t0.05830616225588788\n",
      "  (8540, 222148)\t0.06406608903022974\n",
      "  (8540, 127212)\t0.05830616225588788\n",
      "  (8540, 222147)\t0.06360379066616362\n",
      "  (8540, 127211)\t0.05465176925184273LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "  (0, 280912)\t0.06622249519600037\n",
      "  (0, 277704)\t0.06109615751832261\n",
      "  (0, 275722)\t0.06409487282579808\n",
      "  (0, 275721)\t0.0589685351481203\n",
      "  (0, 275029)\t0.06622249519600037\n",
      "  (0, 275027)\t0.05661333353118344\n",
      "  (0, 274305)\t0.04347485715239196\n",
      "  (0, 273462)\t0.06409487282579808\n",
      "  (0, 273461)\t0.054829761191917806\n",
      "  (0, 268234)\t0.054829761191917806\n",
      "  (0, 268233)\t0.042821867814246406\n",
      "  (0, 267419)\t0.04587285006678963\n",
      "  (0, 267418)\t0.04512516927471607\n",
      "  (0, 267417)\t0.0448460515480161\n",
      "  (0, 267026)\t0.05731822302579619\n",
      "  (0, 256569)\t0.05731822302579619\n",
      "  (0, 255406)\t0.04394458591119463\n",
      "  (0, 254037)\t0.06109615751832261\n",
      "  (0, 254028)\t0.04314115805658861\n",
      "  (0, 252560)\t0.06409487282579808\n",
      "  (0, 251738)\t0.05537784463007162\n",
      "  (0, 251737)\t0.054829761191917806\n",
      "  (0, 251736)\t0.05431950771832071\n",
      "  (0, 247830)\t0.06409487282579808\n",
      "  (0, 243658)\t0.046031904410831014\n",
      "  :\t:\n",
      "  (801, 17617)\t0.04485464583995255\n",
      "  (801, 17616)\t0.042892583751617835\n",
      "  (801, 16677)\t0.03890857439135519\n",
      "  (801, 15409)\t0.03783434558678772\n",
      "  (801, 14921)\t0.045677361536047165\n",
      "  (801, 12606)\t0.05202106872631554\n",
      "  (801, 12605)\t0.05202106872631554\n",
      "  (801, 12604)\t0.05089774631079505\n",
      "  (801, 11430)\t0.04994799074122533\n",
      "  (801, 11429)\t0.04994799074122533\n",
      "  (801, 11428)\t0.04994799074122533\n",
      "  (801, 11414)\t0.03834807765451711\n",
      "  (801, 10192)\t0.046133956728370604\n",
      "  (801, 10191)\t0.045677361536047165\n",
      "  (801, 10187)\t0.04235648790043873\n",
      "  (801, 10186)\t0.03576126760169751\n",
      "  (801, 9627)\t0.04235648790043873\n",
      "  (801, 9626)\t0.04235648790043873\n",
      "  (801, 8747)\t0.03783434558678772\n",
      "  (801, 8702)\t0.041863327523192446\n",
      "  (801, 8508)\t0.03576126760169751\n",
      "  (801, 8507)\t0.035502717124583166\n",
      "  (801, 6286)\t0.04994799074122533\n",
      "  (801, 6285)\t0.04994799074122533\n",
      "  (801, 6281)\t0.04662711710561689LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 118064)\t0.06832140888518141\n",
      "  (0, 85771)\t0.07235548395633176\n",
      "  (0, 56560)\t0.07235548395633176\n",
      "  (0, 6845)\t0.07235548395633176\n",
      "  (0, 259821)\t0.07991781952198222\n",
      "  (0, 246494)\t0.07535857894903215\n",
      "  (0, 242057)\t0.07373131555349188\n",
      "  (0, 226599)\t0.06497718044864063\n",
      "  (0, 28501)\t0.07535857894903215\n",
      "  (0, 190313)\t0.07991781952198222\n",
      "  (0, 195588)\t0.071163684417131\n",
      "  (0, 148673)\t0.07735018838562135\n",
      "  (0, 275133)\t0.06832140888518141\n",
      "  (0, 109801)\t0.06832140888518141\n",
      "  (0, 119919)\t0.06392593875287204\n",
      "  (0, 13785)\t0.060643907352672506\n",
      "  (0, 231321)\t0.07991781952198222\n",
      "  (0, 266865)\t0.07535857894903215\n",
      "  (0, 26090)\t0.06555320214841232\n",
      "  (0, 215447)\t0.07535857894903215\n",
      "  (0, 285548)\t0.06392593875287204\n",
      "  (0, 115077)\t0.05679906704356107\n",
      "  (0, 13011)\t0.055747825347792476\n",
      "  (0, 181459)\t0.06832140888518141\n",
      "  (0, 145831)\t0.06754481158500153\n",
      "  :\t:\n",
      "  (8540, 23369)\t0.05670474985797117\n",
      "  (8540, 195402)\t0.05312049605707629\n",
      "  (8540, 97960)\t0.053853651462524396\n",
      "  (8540, 274342)\t0.051571636823327834\n",
      "  (8540, 237977)\t0.05629500465807332\n",
      "  (8540, 175576)\t0.05312049605707629\n",
      "  (8540, 175572)\t0.05244251923782887\n",
      "  (8540, 44409)\t0.05629500465807332\n",
      "  (8540, 249799)\t0.07080061446278979\n",
      "  (8540, 166048)\t0.05416446992273363\n",
      "  (8540, 44408)\t0.05629500465807332\n",
      "  (8540, 249798)\t0.07080061446278979\n",
      "  (8540, 166047)\t0.054007720891501444\n",
      "  (8540, 44407)\t0.05629500465807332\n",
      "  (8540, 249795)\t0.059367722160527235\n",
      "  (8540, 166046)\t0.054007720891501444\n",
      "  (8540, 249782)\t0.05355319556984793\n",
      "  (8540, 79808)\t0.05312049605707629\n",
      "  (8540, 79806)\t0.052707621941292554\n",
      "  (8540, 79805)\t0.052574095912135174\n",
      "  (8540, 127213)\t0.05830616225588788\n",
      "  (8540, 222148)\t0.06406608903022974\n",
      "  (8540, 127212)\t0.05830616225588788\n",
      "  (8540, 222147)\t0.06360379066616362\n",
      "  (8540, 127211)\t0.05465176925184273ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 4855)\t0.06109615751832261\n",
      "  (0, 5027)\t0.06622249519600037\n",
      "  (0, 6932)\t0.0589685351481203\n",
      "  (0, 7563)\t0.04431755949071081\n",
      "  (0, 8117)\t0.044710346053503776\n",
      "  (0, 8118)\t0.054829761191917806\n",
      "  (0, 8720)\t0.04784476685549158\n",
      "  (0, 9689)\t0.042515793435146866\n",
      "  (0, 9800)\t0.06109615751832261\n",
      "  (0, 10052)\t0.04512516927471607\n",
      "  (0, 10186)\t0.042926773714238135\n",
      "  (0, 10187)\t0.05084348216296706\n",
      "  (0, 10188)\t0.05809744221084713\n",
      "  (0, 11208)\t0.04784476685549158\n",
      "  (0, 11209)\t0.05537784463007162\n",
      "  (0, 11212)\t0.0589685351481203\n",
      "  (0, 12617)\t0.051831045884442324\n",
      "  (0, 12618)\t0.052571237316943714\n",
      "  (0, 12619)\t0.0589685351481203\n",
      "  (0, 15832)\t0.044984293740185095\n",
      "  (0, 15849)\t0.05731822302579619\n",
      "  (0, 16427)\t0.05339383341194416\n",
      "  (0, 16428)\t0.05339383341194416\n",
      "  (0, 17122)\t0.052971104533169354\n",
      "  (0, 17123)\t0.05339383341194416\n",
      "  :\t:\n",
      "  (801, 271564)\t0.04525228158162355\n",
      "  (801, 271565)\t0.04525228158162355\n",
      "  (801, 271566)\t0.04912527504513071\n",
      "  (801, 274693)\t0.0353361876472739\n",
      "  (801, 274697)\t0.03567387300764823\n",
      "  (801, 274700)\t0.036123796606925856\n",
      "  (801, 274701)\t0.036123796606925856\n",
      "  (801, 275169)\t0.03724711902244634\n",
      "  (801, 275181)\t0.040981652376445396\n",
      "  (801, 275182)\t0.040981652376445396\n",
      "  (801, 280373)\t0.04140673233086901\n",
      "  (801, 280379)\t0.047750439521137375\n",
      "  (801, 280380)\t0.047750439521137375\n",
      "  (801, 282127)\t0.03478641539630425\n",
      "  (801, 282128)\t0.039689518974396536\n",
      "  (801, 282646)\t0.039365169583678625\n",
      "  (801, 282661)\t0.04716321295679599\n",
      "  (801, 282665)\t0.04994799074122533\n",
      "  (801, 282666)\t0.0551683755159732\n",
      "  (801, 283458)\t0.03567387300764823\n",
      "  (801, 283460)\t0.03584991971500329\n",
      "  (801, 283461)\t0.03584991971500329\n",
      "  (801, 283462)\t0.03584991971500329\n",
      "  (801, 283465)\t0.04448112447574099\n",
      "  (801, 285320)\t0.04210497479196588ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 118064)\t0.06832140888518141\n",
      "  (0, 85771)\t0.07235548395633176\n",
      "  (0, 56560)\t0.07235548395633176\n",
      "  (0, 6845)\t0.07235548395633176\n",
      "  (0, 259821)\t0.07991781952198222\n",
      "  (0, 246494)\t0.07535857894903215\n",
      "  (0, 242057)\t0.07373131555349188\n",
      "  (0, 226599)\t0.06497718044864063\n",
      "  (0, 28501)\t0.07535857894903215\n",
      "  (0, 190313)\t0.07991781952198222\n",
      "  (0, 195588)\t0.071163684417131\n",
      "  (0, 148673)\t0.07735018838562135\n",
      "  (0, 275133)\t0.06832140888518141\n",
      "  (0, 109801)\t0.06832140888518141\n",
      "  (0, 119919)\t0.06392593875287204\n",
      "  (0, 13785)\t0.060643907352672506\n",
      "  (0, 231321)\t0.07991781952198222\n",
      "  (0, 266865)\t0.07535857894903215\n",
      "  (0, 26090)\t0.06555320214841232\n",
      "  (0, 215447)\t0.07535857894903215\n",
      "  (0, 285548)\t0.06392593875287204\n",
      "  (0, 115077)\t0.05679906704356107\n",
      "  (0, 13011)\t0.055747825347792476\n",
      "  (0, 181459)\t0.06832140888518141\n",
      "  (0, 145831)\t0.06754481158500153\n",
      "  :\t:\n",
      "  (8540, 23369)\t0.05670474985797117\n",
      "  (8540, 195402)\t0.05312049605707629\n",
      "  (8540, 97960)\t0.053853651462524396\n",
      "  (8540, 274342)\t0.051571636823327834\n",
      "  (8540, 237977)\t0.05629500465807332\n",
      "  (8540, 175576)\t0.05312049605707629\n",
      "  (8540, 175572)\t0.05244251923782887\n",
      "  (8540, 44409)\t0.05629500465807332\n",
      "  (8540, 249799)\t0.07080061446278979\n",
      "  (8540, 166048)\t0.05416446992273363\n",
      "  (8540, 44408)\t0.05629500465807332\n",
      "  (8540, 249798)\t0.07080061446278979\n",
      "  (8540, 166047)\t0.054007720891501444\n",
      "  (8540, 44407)\t0.05629500465807332\n",
      "  (8540, 249795)\t0.059367722160527235\n",
      "  (8540, 166046)\t0.054007720891501444\n",
      "  (8540, 249782)\t0.05355319556984793\n",
      "  (8540, 79808)\t0.05312049605707629\n",
      "  (8540, 79806)\t0.052707621941292554\n",
      "  (8540, 79805)\t0.052574095912135174\n",
      "  (8540, 127213)\t0.05830616225588788\n",
      "  (8540, 222148)\t0.06406608903022974\n",
      "  (8540, 127212)\t0.05830616225588788\n",
      "  (8540, 222147)\t0.06360379066616362\n",
      "  (8540, 127211)\t0.05465176925184273ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 4855)\t0.06109615751832261\n",
      "  (0, 5027)\t0.06622249519600037\n",
      "  (0, 6932)\t0.0589685351481203\n",
      "  (0, 7563)\t0.04431755949071081\n",
      "  (0, 8117)\t0.044710346053503776\n",
      "  (0, 8118)\t0.054829761191917806\n",
      "  (0, 8720)\t0.04784476685549158\n",
      "  (0, 9689)\t0.042515793435146866\n",
      "  (0, 9800)\t0.06109615751832261\n",
      "  (0, 10052)\t0.04512516927471607\n",
      "  (0, 10186)\t0.042926773714238135\n",
      "  (0, 10187)\t0.05084348216296706\n",
      "  (0, 10188)\t0.05809744221084713\n",
      "  (0, 11208)\t0.04784476685549158\n",
      "  (0, 11209)\t0.05537784463007162\n",
      "  (0, 11212)\t0.0589685351481203\n",
      "  (0, 12617)\t0.051831045884442324\n",
      "  (0, 12618)\t0.052571237316943714\n",
      "  (0, 12619)\t0.0589685351481203\n",
      "  (0, 15832)\t0.044984293740185095\n",
      "  (0, 15849)\t0.05731822302579619\n",
      "  (0, 16427)\t0.05339383341194416\n",
      "  (0, 16428)\t0.05339383341194416\n",
      "  (0, 17122)\t0.052971104533169354\n",
      "  (0, 17123)\t0.05339383341194416\n",
      "  :\t:\n",
      "  (801, 271564)\t0.04525228158162355\n",
      "  (801, 271565)\t0.04525228158162355\n",
      "  (801, 271566)\t0.04912527504513071\n",
      "  (801, 274693)\t0.0353361876472739\n",
      "  (801, 274697)\t0.03567387300764823\n",
      "  (801, 274700)\t0.036123796606925856\n",
      "  (801, 274701)\t0.036123796606925856\n",
      "  (801, 275169)\t0.03724711902244634\n",
      "  (801, 275181)\t0.040981652376445396\n",
      "  (801, 275182)\t0.040981652376445396\n",
      "  (801, 280373)\t0.04140673233086901\n",
      "  (801, 280379)\t0.047750439521137375\n",
      "  (801, 280380)\t0.047750439521137375\n",
      "  (801, 282127)\t0.03478641539630425\n",
      "  (801, 282128)\t0.039689518974396536\n",
      "  (801, 282646)\t0.039365169583678625\n",
      "  (801, 282661)\t0.04716321295679599\n",
      "  (801, 282665)\t0.04994799074122533\n",
      "  (801, 282666)\t0.0551683755159732\n",
      "  (801, 283458)\t0.03567387300764823\n",
      "  (801, 283460)\t0.03584991971500329\n",
      "  (801, 283461)\t0.03584991971500329\n",
      "  (801, 283462)\t0.03584991971500329\n",
      "  (801, 283465)\t0.04448112447574099\n",
      "  (801, 285320)\t0.04210497479196588ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 27994)\t0.3838999798572487\n",
      "  (0, 167)\t0.3838999798572487\n",
      "  (0, 11815)\t0.2750439403096284\n",
      "  (0, 12577)\t0.37156589032095133\n",
      "  (0, 29225)\t0.3541819674903452\n",
      "  (0, 27993)\t0.336798044659739\n",
      "  (0, 12836)\t0.309530643789222\n",
      "  (0, 19704)\t0.309530643789222\n",
      "  (0, 12574)\t0.24705263226499857\n",
      "  (1, 820)\t0.2586172666205532\n",
      "  (1, 3661)\t0.2586172666205532\n",
      "  (1, 13449)\t0.243863381418298\n",
      "  (1, 29037)\t0.23028853460577484\n",
      "  (1, 5921)\t0.243863381418298\n",
      "  (1, 6299)\t0.2141254709135135\n",
      "  (1, 819)\t0.22688667435053542\n",
      "  (1, 26623)\t0.23859749185895449\n",
      "  (1, 1352)\t0.21626588921451245\n",
      "  (1, 22167)\t0.2010710423207007\n",
      "  (1, 3660)\t0.2586172666205532\n",
      "  (1, 16276)\t0.17976739264857394\n",
      "  (1, 13448)\t0.23028853460577484\n",
      "  (1, 23782)\t0.2010710423207007\n",
      "  (1, 17544)\t0.21026875984417612\n",
      "  (1, 22586)\t0.2586172666205532\n",
      "  :\t:\n",
      "  (8539, 15326)\t0.3597472849220919\n",
      "  (8539, 16148)\t0.3333514554024809\n",
      "  (8539, 13153)\t0.37740436408938804\n",
      "  (8539, 13152)\t0.3472193878806087\n",
      "  (8539, 7139)\t0.3198449168281999\n",
      "  (8539, 13148)\t0.2527620544635877\n",
      "  (8539, 28108)\t0.27298150298492224\n",
      "  (8540, 15670)\t0.26420752111345863\n",
      "  (8540, 15669)\t0.25571895796534816\n",
      "  (8540, 23775)\t0.26420752111345863\n",
      "  (8540, 19362)\t0.26420752111345863\n",
      "  (8540, 6854)\t0.26420752111345863\n",
      "  (8540, 21079)\t0.24913471686098887\n",
      "  (8540, 28661)\t0.25571895796534816\n",
      "  (8540, 28660)\t0.24375500016568905\n",
      "  (8540, 12102)\t0.2082296749654496\n",
      "  (8540, 15690)\t0.19529819604333695\n",
      "  (8540, 24022)\t0.21671823811356009\n",
      "  (8540, 19359)\t0.2041057541960977\n",
      "  (8540, 28721)\t0.20541738126556194\n",
      "  (8540, 17321)\t0.1962657171657905\n",
      "  (8540, 16322)\t0.22868219591321923\n",
      "  (8540, 28521)\t0.26420752111345863\n",
      "  (8540, 23774)\t0.24913471686098887\n",
      "  (8540, 28516)\t0.183018655015703LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "  (0, 31012)\t0.19629602813319552\n",
      "  (0, 29339)\t0.17777813051935185\n",
      "  (0, 24499)\t0.21017981802632119\n",
      "  (0, 22562)\t0.18007468395740253\n",
      "  (0, 21087)\t0.19764751506211392\n",
      "  (0, 20864)\t0.20288964725449063\n",
      "  (0, 18754)\t0.28433999818661776\n",
      "  (0, 18150)\t0.25743392775219864\n",
      "  (0, 18144)\t0.28433999818661776\n",
      "  (0, 17590)\t0.24945340044929512\n",
      "  (0, 16637)\t0.22744240793593953\n",
      "  (0, 11370)\t0.24945340044929512\n",
      "  (0, 10183)\t0.25743392775219864\n",
      "  (0, 9006)\t0.24945340044929512\n",
      "  (0, 8896)\t0.22925748192656017\n",
      "  (0, 7855)\t0.17968020497464973\n",
      "  (0, 6261)\t0.2531936183838738\n",
      "  (0, 5462)\t0.23542293523884308\n",
      "  (0, 5077)\t0.18974378380569382\n",
      "  (1, 29553)\t0.2658389200236334\n",
      "  (1, 21441)\t0.3626991640001594\n",
      "  (1, 21436)\t0.26966517287340536\n",
      "  (1, 14323)\t0.311466067756722\n",
      "  (1, 13105)\t0.33858451847566556\n",
      "  (1, 11120)\t0.2894327227328889\n",
      "  :\t:\n",
      "  (800, 11859)\t0.21793303782177145\n",
      "  (800, 10090)\t0.3006207077206833\n",
      "  (800, 9331)\t0.27969280266254987\n",
      "  (800, 1942)\t0.27594148436932153\n",
      "  (801, 30265)\t0.21631981695297126\n",
      "  (801, 29054)\t0.1885965321210265\n",
      "  (801, 28744)\t0.24189499299482195\n",
      "  (801, 28741)\t0.1682345777558774\n",
      "  (801, 27283)\t0.22627519919534358\n",
      "  (801, 27186)\t0.24992467112109729\n",
      "  (801, 25255)\t0.17372508445815196\n",
      "  (801, 24777)\t0.21631981695297126\n",
      "  (801, 23291)\t0.24992467112109729\n",
      "  (801, 18165)\t0.24992467112109729\n",
      "  (801, 16232)\t0.24992467112109729\n",
      "  (801, 16231)\t0.22627519919534358\n",
      "  (801, 11736)\t0.19074464091112056\n",
      "  (801, 10650)\t0.24189499299482195\n",
      "  (801, 10312)\t0.19697294313981586\n",
      "  (801, 9011)\t0.21365955363011704\n",
      "  (801, 7632)\t0.19188404968163117\n",
      "  (801, 5183)\t0.24992467112109729\n",
      "  (801, 5179)\t0.16161035911725982\n",
      "  (801, 3887)\t0.22627519919534358\n",
      "  (801, 3577)\t0.21365955363011704LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 27994)\t0.3838999798572487\n",
      "  (0, 167)\t0.3838999798572487\n",
      "  (0, 11815)\t0.2750439403096284\n",
      "  (0, 12577)\t0.37156589032095133\n",
      "  (0, 29225)\t0.3541819674903452\n",
      "  (0, 27993)\t0.336798044659739\n",
      "  (0, 12836)\t0.309530643789222\n",
      "  (0, 19704)\t0.309530643789222\n",
      "  (0, 12574)\t0.24705263226499857\n",
      "  (1, 820)\t0.2586172666205532\n",
      "  (1, 3661)\t0.2586172666205532\n",
      "  (1, 13449)\t0.243863381418298\n",
      "  (1, 29037)\t0.23028853460577484\n",
      "  (1, 5921)\t0.243863381418298\n",
      "  (1, 6299)\t0.2141254709135135\n",
      "  (1, 819)\t0.22688667435053542\n",
      "  (1, 26623)\t0.23859749185895449\n",
      "  (1, 1352)\t0.21626588921451245\n",
      "  (1, 22167)\t0.2010710423207007\n",
      "  (1, 3660)\t0.2586172666205532\n",
      "  (1, 16276)\t0.17976739264857394\n",
      "  (1, 13448)\t0.23028853460577484\n",
      "  (1, 23782)\t0.2010710423207007\n",
      "  (1, 17544)\t0.21026875984417612\n",
      "  (1, 22586)\t0.2586172666205532\n",
      "  :\t:\n",
      "  (8539, 15326)\t0.3597472849220919\n",
      "  (8539, 16148)\t0.3333514554024809\n",
      "  (8539, 13153)\t0.37740436408938804\n",
      "  (8539, 13152)\t0.3472193878806087\n",
      "  (8539, 7139)\t0.3198449168281999\n",
      "  (8539, 13148)\t0.2527620544635877\n",
      "  (8539, 28108)\t0.27298150298492224\n",
      "  (8540, 15670)\t0.26420752111345863\n",
      "  (8540, 15669)\t0.25571895796534816\n",
      "  (8540, 23775)\t0.26420752111345863\n",
      "  (8540, 19362)\t0.26420752111345863\n",
      "  (8540, 6854)\t0.26420752111345863\n",
      "  (8540, 21079)\t0.24913471686098887\n",
      "  (8540, 28661)\t0.25571895796534816\n",
      "  (8540, 28660)\t0.24375500016568905\n",
      "  (8540, 12102)\t0.2082296749654496\n",
      "  (8540, 15690)\t0.19529819604333695\n",
      "  (8540, 24022)\t0.21671823811356009\n",
      "  (8540, 19359)\t0.2041057541960977\n",
      "  (8540, 28721)\t0.20541738126556194\n",
      "  (8540, 17321)\t0.1962657171657905\n",
      "  (8540, 16322)\t0.22868219591321923\n",
      "  (8540, 28521)\t0.26420752111345863\n",
      "  (8540, 23774)\t0.24913471686098887\n",
      "  (8540, 28516)\t0.183018655015703ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 5077)\t0.18974378380569382\n",
      "  (0, 5462)\t0.23542293523884308\n",
      "  (0, 6261)\t0.2531936183838738\n",
      "  (0, 7855)\t0.17968020497464973\n",
      "  (0, 8896)\t0.22925748192656017\n",
      "  (0, 9006)\t0.24945340044929512\n",
      "  (0, 10183)\t0.25743392775219864\n",
      "  (0, 11370)\t0.24945340044929512\n",
      "  (0, 16637)\t0.22744240793593953\n",
      "  (0, 17590)\t0.24945340044929512\n",
      "  (0, 18144)\t0.28433999818661776\n",
      "  (0, 18150)\t0.25743392775219864\n",
      "  (0, 18754)\t0.28433999818661776\n",
      "  (0, 20864)\t0.20288964725449063\n",
      "  (0, 21087)\t0.19764751506211392\n",
      "  (0, 22562)\t0.18007468395740253\n",
      "  (0, 24499)\t0.21017981802632119\n",
      "  (0, 29339)\t0.17777813051935185\n",
      "  (0, 31012)\t0.19629602813319552\n",
      "  (1, 7304)\t0.36959584885125024\n",
      "  (1, 7567)\t0.3777528957107077\n",
      "  (1, 8600)\t0.3877363142184422\n",
      "  (1, 11120)\t0.2894327227328889\n",
      "  (1, 13105)\t0.33858451847566556\n",
      "  (1, 14323)\t0.311466067756722\n",
      "  :\t:\n",
      "  (800, 24666)\t0.2838864197261251\n",
      "  (800, 25901)\t0.31880844622137994\n",
      "  (800, 30924)\t0.3006207077206833\n",
      "  (800, 31069)\t0.3085656430774868\n",
      "  (801, 3577)\t0.21365955363011704\n",
      "  (801, 3887)\t0.22627519919534358\n",
      "  (801, 5179)\t0.16161035911725982\n",
      "  (801, 5183)\t0.24992467112109729\n",
      "  (801, 7632)\t0.19188404968163117\n",
      "  (801, 9011)\t0.21365955363011704\n",
      "  (801, 10312)\t0.19697294313981586\n",
      "  (801, 10650)\t0.24189499299482195\n",
      "  (801, 11736)\t0.19074464091112056\n",
      "  (801, 16231)\t0.22627519919534358\n",
      "  (801, 16232)\t0.24992467112109729\n",
      "  (801, 18165)\t0.24992467112109729\n",
      "  (801, 23291)\t0.24992467112109729\n",
      "  (801, 24777)\t0.21631981695297126\n",
      "  (801, 25255)\t0.17372508445815196\n",
      "  (801, 27186)\t0.24992467112109729\n",
      "  (801, 27283)\t0.22627519919534358\n",
      "  (801, 28741)\t0.1682345777558774\n",
      "  (801, 28744)\t0.24189499299482195\n",
      "  (801, 29054)\t0.1885965321210265\n",
      "  (801, 30265)\t0.21631981695297126ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "  (0, 27994)\t0.3838999798572487\n",
      "  (0, 167)\t0.3838999798572487\n",
      "  (0, 11815)\t0.2750439403096284\n",
      "  (0, 12577)\t0.37156589032095133\n",
      "  (0, 29225)\t0.3541819674903452\n",
      "  (0, 27993)\t0.336798044659739\n",
      "  (0, 12836)\t0.309530643789222\n",
      "  (0, 19704)\t0.309530643789222\n",
      "  (0, 12574)\t0.24705263226499857\n",
      "  (1, 820)\t0.2586172666205532\n",
      "  (1, 3661)\t0.2586172666205532\n",
      "  (1, 13449)\t0.243863381418298\n",
      "  (1, 29037)\t0.23028853460577484\n",
      "  (1, 5921)\t0.243863381418298\n",
      "  (1, 6299)\t0.2141254709135135\n",
      "  (1, 819)\t0.22688667435053542\n",
      "  (1, 26623)\t0.23859749185895449\n",
      "  (1, 1352)\t0.21626588921451245\n",
      "  (1, 22167)\t0.2010710423207007\n",
      "  (1, 3660)\t0.2586172666205532\n",
      "  (1, 16276)\t0.17976739264857394\n",
      "  (1, 13448)\t0.23028853460577484\n",
      "  (1, 23782)\t0.2010710423207007\n",
      "  (1, 17544)\t0.21026875984417612\n",
      "  (1, 22586)\t0.2586172666205532\n",
      "  :\t:\n",
      "  (8539, 15326)\t0.3597472849220919\n",
      "  (8539, 16148)\t0.3333514554024809\n",
      "  (8539, 13153)\t0.37740436408938804\n",
      "  (8539, 13152)\t0.3472193878806087\n",
      "  (8539, 7139)\t0.3198449168281999\n",
      "  (8539, 13148)\t0.2527620544635877\n",
      "  (8539, 28108)\t0.27298150298492224\n",
      "  (8540, 15670)\t0.26420752111345863\n",
      "  (8540, 15669)\t0.25571895796534816\n",
      "  (8540, 23775)\t0.26420752111345863\n",
      "  (8540, 19362)\t0.26420752111345863\n",
      "  (8540, 6854)\t0.26420752111345863\n",
      "  (8540, 21079)\t0.24913471686098887\n",
      "  (8540, 28661)\t0.25571895796534816\n",
      "  (8540, 28660)\t0.24375500016568905\n",
      "  (8540, 12102)\t0.2082296749654496\n",
      "  (8540, 15690)\t0.19529819604333695\n",
      "  (8540, 24022)\t0.21671823811356009\n",
      "  (8540, 19359)\t0.2041057541960977\n",
      "  (8540, 28721)\t0.20541738126556194\n",
      "  (8540, 17321)\t0.1962657171657905\n",
      "  (8540, 16322)\t0.22868219591321923\n",
      "  (8540, 28521)\t0.26420752111345863\n",
      "  (8540, 23774)\t0.24913471686098887\n",
      "  (8540, 28516)\t0.183018655015703ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "  (0, 5077)\t0.18974378380569382\n",
      "  (0, 5462)\t0.23542293523884308\n",
      "  (0, 6261)\t0.2531936183838738\n",
      "  (0, 7855)\t0.17968020497464973\n",
      "  (0, 8896)\t0.22925748192656017\n",
      "  (0, 9006)\t0.24945340044929512\n",
      "  (0, 10183)\t0.25743392775219864\n",
      "  (0, 11370)\t0.24945340044929512\n",
      "  (0, 16637)\t0.22744240793593953\n",
      "  (0, 17590)\t0.24945340044929512\n",
      "  (0, 18144)\t0.28433999818661776\n",
      "  (0, 18150)\t0.25743392775219864\n",
      "  (0, 18754)\t0.28433999818661776\n",
      "  (0, 20864)\t0.20288964725449063\n",
      "  (0, 21087)\t0.19764751506211392\n",
      "  (0, 22562)\t0.18007468395740253\n",
      "  (0, 24499)\t0.21017981802632119\n",
      "  (0, 29339)\t0.17777813051935185\n",
      "  (0, 31012)\t0.19629602813319552\n",
      "  (1, 7304)\t0.36959584885125024\n",
      "  (1, 7567)\t0.3777528957107077\n",
      "  (1, 8600)\t0.3877363142184422\n",
      "  (1, 11120)\t0.2894327227328889\n",
      "  (1, 13105)\t0.33858451847566556\n",
      "  (1, 14323)\t0.311466067756722\n",
      "  :\t:\n",
      "  (800, 24666)\t0.2838864197261251\n",
      "  (800, 25901)\t0.31880844622137994\n",
      "  (800, 30924)\t0.3006207077206833\n",
      "  (800, 31069)\t0.3085656430774868\n",
      "  (801, 3577)\t0.21365955363011704\n",
      "  (801, 3887)\t0.22627519919534358\n",
      "  (801, 5179)\t0.16161035911725982\n",
      "  (801, 5183)\t0.24992467112109729\n",
      "  (801, 7632)\t0.19188404968163117\n",
      "  (801, 9011)\t0.21365955363011704\n",
      "  (801, 10312)\t0.19697294313981586\n",
      "  (801, 10650)\t0.24189499299482195\n",
      "  (801, 11736)\t0.19074464091112056\n",
      "  (801, 16231)\t0.22627519919534358\n",
      "  (801, 16232)\t0.24992467112109729\n",
      "  (801, 18165)\t0.24992467112109729\n",
      "  (801, 23291)\t0.24992467112109729\n",
      "  (801, 24777)\t0.21631981695297126\n",
      "  (801, 25255)\t0.17372508445815196\n",
      "  (801, 27186)\t0.24992467112109729\n",
      "  (801, 27283)\t0.22627519919534358\n",
      "  (801, 28741)\t0.1682345777558774\n",
      "  (801, 28744)\t0.24189499299482195\n",
      "  (801, 29054)\t0.1885965321210265\n",
      "  (801, 30265)\t0.21631981695297126ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[-0.11466956 -0.01908347  0.00172211 ...  0.06156928  0.08135319\n",
      "  -0.07859743]\n",
      " [-0.12918881 -0.02765546  0.11615171 ... -0.00593668 -0.0802549\n",
      "  -0.00568726]\n",
      " [-0.04746682 -0.10253195 -0.02464943 ...  0.13990997 -0.00122685\n",
      "   0.00821853]\n",
      " ...\n",
      " [-0.08659905 -0.00710907  0.0022457  ...  0.01209016  0.03789412\n",
      "  -0.08774336]\n",
      " [-0.17021359  0.03429338 -0.02271174 ...  0.0431119  -0.16762087\n",
      "  -0.16246864]\n",
      " [-0.06326013 -0.02837186  0.08405035 ... -0.06740867 -0.03769415\n",
      "  -0.08349329]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 8541\n",
      "[[-0.16421218 -0.00073272  0.04691822 ... -0.01254562 -0.07327801\n",
      "  -0.10237613]\n",
      " [-0.11650738  0.07978699  0.0179863  ...  0.04880052  0.00380368\n",
      "  -0.0271589 ]\n",
      " [-0.11894281  0.04145353  0.0978137  ... -0.02193728 -0.11535163\n",
      "  -0.0523463 ]\n",
      " ...\n",
      " [-0.06988689 -0.06927601  0.05345311 ... -0.09653039 -0.05638778\n",
      "  -0.02115867]\n",
      " [-0.15832969 -0.09984014 -0.06836596 ... -0.004405   -0.06729489\n",
      "   0.05255853]\n",
      " [-0.10925703  0.03403725  0.02126907 ...  0.00416451 -0.03184644\n",
      "  -0.03990714]]LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=200, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): 802\n",
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[-0.11466956 -0.01908347  0.00172211 ...  0.06156928  0.08135319\n",
      "  -0.07859743]\n",
      " [-0.12918881 -0.02765546  0.11615171 ... -0.00593668 -0.0802549\n",
      "  -0.00568726]\n",
      " [-0.04746682 -0.10253195 -0.02464943 ...  0.13990997 -0.00122685\n",
      "   0.00821853]\n",
      " ...\n",
      " [-0.08659905 -0.00710907  0.0022457  ...  0.01209016  0.03789412\n",
      "  -0.08774336]\n",
      " [-0.17021359  0.03429338 -0.02271174 ...  0.0431119  -0.16762087\n",
      "  -0.16246864]\n",
      " [-0.06326013 -0.02837186  0.08405035 ... -0.06740867 -0.03769415\n",
      "  -0.08349329]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[-0.16421218 -0.00073272  0.04691822 ... -0.01254562 -0.07327801\n",
      "  -0.10237613]\n",
      " [-0.11650738  0.07978699  0.0179863  ...  0.04880052  0.00380368\n",
      "  -0.0271589 ]\n",
      " [-0.11894281  0.04145353  0.0978137  ... -0.02193728 -0.11535163\n",
      "  -0.0523463 ]\n",
      " ...\n",
      " [-0.06988689 -0.06927601  0.05345311 ... -0.09653039 -0.05638778\n",
      "  -0.02115867]\n",
      " [-0.15832969 -0.09984014 -0.06836596 ... -0.004405   -0.06729489\n",
      "   0.05255853]\n",
      " [-0.10925703  0.03403725  0.02126907 ...  0.00416451 -0.03184644\n",
      "  -0.03990714]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='entropy', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge bzw Anzahl an Features_train: 8541\n",
      "Classifier: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Länge bzw Anzahl an Features_mdp: 802\n",
      "[[-0.11466956 -0.01908347  0.00172211 ...  0.06156928  0.08135319\n",
      "  -0.07859743]\n",
      " [-0.12918881 -0.02765546  0.11615171 ... -0.00593668 -0.0802549\n",
      "  -0.00568726]\n",
      " [-0.04746682 -0.10253195 -0.02464943 ...  0.13990997 -0.00122685\n",
      "   0.00821853]\n",
      " ...\n",
      " [-0.08659905 -0.00710907  0.0022457  ...  0.01209016  0.03789412\n",
      "  -0.08774336]\n",
      " [-0.17021359  0.03429338 -0.02271174 ...  0.0431119  -0.16762087\n",
      "  -0.16246864]\n",
      " [-0.06326013 -0.02837186  0.08405035 ... -0.06740867 -0.03769415\n",
      "  -0.08349329]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 8541\n",
      "[[-0.16421218 -0.00073272  0.04691822 ... -0.01254562 -0.07327801\n",
      "  -0.10237613]\n",
      " [-0.11650738  0.07978699  0.0179863  ...  0.04880052  0.00380368\n",
      "  -0.0271589 ]\n",
      " [-0.11894281  0.04145353  0.0978137  ... -0.02193728 -0.11535163\n",
      "  -0.0523463 ]\n",
      " ...\n",
      " [-0.06988689 -0.06927601  0.05345311 ... -0.09653039 -0.05638778\n",
      "  -0.02115867]\n",
      " [-0.15832969 -0.09984014 -0.06836596 ... -0.004405   -0.06729489\n",
      "   0.05255853]\n",
      " [-0.10925703  0.03403725  0.02126907 ...  0.00416451 -0.03184644\n",
      "  -0.03990714]]ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False): 802\n",
      "train: (8541, 30)\n",
      "mdp: (802, 30)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter\n",
    "from datetime import datetime\n",
    "processed_weeks = []\n",
    "\n",
    "#for week in set(sample_df['Woche']):\n",
    "#    print(\"%s: starting labeling\" % (datetime.now().strftime(\"%H:%M:%S\")))\n",
    "#    print(week)\n",
    "#    if week not in processed_weeks:\n",
    "i=1\n",
    "for i in range(0,2):\n",
    "        #sample_mdp = np.array(sample_df[sample_df['Woche'] == week]['full_text_processed'])\n",
    "        sample_mdp= np.array(df_test_rand['Text']) # Zur Evaluation der Ergebnisse/ des Alorithmus\n",
    "        word2vec_model  = gensim.models.KeyedVectors.load_word2vec_format(MODEL_FILENAME, binary=True)\n",
    "\n",
    "        X_train, y_train_t1, y_train_t2 = get_train_data(TRAIN_FILENAME)\n",
    "        X_test_mdp                      = sample_mdp\n",
    "\n",
    "    ### NGRAM FEATURES\n",
    "    #  * Erstelle n-Gramme mit 3-7 Buchstaben (Funktion: char_vect)\n",
    "    #  * Erstelle n-Gramme mit 1-3 Wörtern /Funkion: token_vect\n",
    "    #  * Anwendung auf Training/ Test und mdp Daten\n",
    "\n",
    "        char_vect  = TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 7), max_df=0.01, min_df=0.0002,\n",
    "                                     preprocessor=Tokenizer(preserve_case=False, join=True).tokenize)\n",
    "\n",
    "        token_vect = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 3), max_df=0.01, min_df=0.0002,\n",
    "                                     tokenizer=Tokenizer(preserve_case=False, use_stemmer=True).tokenize)\n",
    "\n",
    "        X_CNGR_train = char_vect.fit_transform(X_train)\n",
    "        X_CNGR_mdp = char_vect.transform(X_test_mdp)\n",
    "\n",
    "        X_TNGR_train = token_vect.fit_transform(X_train)\n",
    "        X_TNGR_mdp  = token_vect.transform(X_test_mdp)\n",
    "        \n",
    "        print('X_CNGR_mdp: ' + str(X_CNGR_mdp.shape))\n",
    "        print('X_CNGR_train: ' + str(X_CNGR_train.shape))\n",
    "        print('X_TNGR_mdp: ' + str(X_TNGR_mdp.shape))\n",
    "        print('X_TNGR_train: ' + str(X_TNGR_train.shape))\n",
    "        \n",
    "        # X_CNGR_train = pickle.load(open(PICKLE_FOLDER_PATH + \"X_CNGR_train.p\", \"rb\" ))\n",
    "        # X_TNGR_train = pickle.load(open(PICKLE_FOLDER_PATH + \"X_TNGR_train.p\", \"rb\" ))\n",
    "\n",
    "        #pickle.dump(X_CNGR_train, open(PICKLE_FOLDER_PATH + \"X_CNGR_train.p\", \"wb\" ))\n",
    "        #pickle.dump(X_TNGR_train, open(PICKLE_FOLDER_PATH + \"X_TNGR_train.p\", \"wb\" ))\n",
    "\n",
    "    ### EMB FEATURES\n",
    "    # * Tweets werden in Token unterteilt\n",
    "    # * Prüfe ob die Token in einem Token im vortrainierten word2vec Model entsprechen\n",
    "    # * Wenn nicht, teile Token in Präfix und Suffix und prüfe für diese das word2vec Model (ggf. beide in emb)\n",
    "    # * emb enthält pro Tweet Vektoren für Token und wird normalisiert mit der Länge des Tweets + ggf extra Tokens\n",
    "    # * X_EMB enthält die normalisierten Vektoren pro Tweet\n",
    "\n",
    "        def get_EMB_feats(tweets):   \n",
    "            tknzr = Tokenizer(preserve_case=True)\n",
    "            tweets = [tknzr.tokenize(tweet) for tweet in tweets]\n",
    "\n",
    "            X_EMB = []\n",
    "\n",
    "            for tweet, i in zip(tweets, range(0,len(tweets))):\n",
    "                emb = np.zeros(MODEL_DIMENSION)\n",
    "                extra_tokens = 0\n",
    "\n",
    "                for token in tweet:\n",
    "                    try:\n",
    "                        emb += word2vec_model[token]\n",
    "                    except:\n",
    "                        prefix = find_subtoken(token, word2vec_model, mode='initial')\n",
    "                        suffix = find_subtoken(token, word2vec_model, mode='final')\n",
    "\n",
    "                        if prefix != None and suffix != None:\n",
    "                            emb += word2vec_model[prefix] + word2vec_model[suffix]\n",
    "                            extra_tokens += 1\n",
    "                        elif prefix != None and suffix == None:\n",
    "                            emb += word2vec_model[prefix]\n",
    "                        elif prefix == None and suffix != None:\n",
    "                            emb += word2vec_model[suffix]           \n",
    "                emb /= (len(tweet) + extra_tokens)\n",
    "        #         print(i)\n",
    "        #         print(len(tweet))\n",
    "                X_EMB.append(emb)\n",
    "\n",
    "            return normalize(X_EMB)\n",
    "        \n",
    "        # X_EMB_train = pickle.load(open(PICKLE_FOLDER_PATH + \"X_EMB_train.p\", \"rb\" ))        \n",
    "\n",
    "        X_EMB_train = get_EMB_feats(X_train)\n",
    "        X_EMB_mdp  = get_EMB_feats(X_test_mdp)\n",
    "        \n",
    "        print('X_EMB_mdp: ' + str(X_EMB_mdp.shape))\n",
    "        print('X_EMB_train: ' + str(X_EMB_train.shape))\n",
    "        pickle.dump(X_EMB_train, open(PICKLE_FOLDER_PATH + \"X_EMB_train.p\", \"wb\" ))\n",
    "\n",
    "    # ### TIMP FEATURES\n",
    "    # * Finden der wichtigen Tokens - also derer die in Tweets der angegebenen Kategorie verwendet werden\n",
    "    # * Für diese wichtigsten Tokens werden die Features analog der EMB Features aus dem word2vec model abgeleitet\n",
    "    # * Außerdem werden für alle Tweets analog der EMB feats abgeleitet\n",
    "    # * Vergleiche mit der Cosine Similarity und gebe die höchsten und niedrigsten Werte pro Tweet zurück\n",
    "\n",
    "        def k_most_imp_tokenlvl(k, category, max_df=0.01, min_df=0.0002):      \n",
    "            token_vect = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1), lowercase=False,\n",
    "                                         max_df=max_df, min_df=min_df,\n",
    "                                         tokenizer=Tokenizer(preserve_case=True).tokenize)\n",
    "\n",
    "            tfidf = token_vect.fit_transform(X_train)\n",
    "\n",
    "            vocab = token_vect.vocabulary_\n",
    "            inv_vocab = {index: word for word, index in vocab.items()}\n",
    "\n",
    "            if category in ['OTHER', 'OFFENSE']:\n",
    "                cat_ids = np.where(y_train_t1 == category)\n",
    "            elif category in ['PROFANITY', 'ABUSE', 'INSULT']:\n",
    "                cat_ids = np.where(y_train_t2 == category)\n",
    "\n",
    "            most_imp_ids = np.argsort(np.asarray(np.mean(tfidf[cat_ids], axis=0)).flatten())[::-1]\n",
    "\n",
    "            most_imp = []\n",
    "            for index in most_imp_ids:\n",
    "                most_imp.append(inv_vocab[index])\n",
    "\n",
    "            return most_imp[:k]\n",
    "\n",
    "        def get_TIMP_feats(tweets, k, category, max_df=0.01, min_df=0.0002):\n",
    "            feats_max = []\n",
    "            feats_min = []\n",
    "\n",
    "            imp_tokens_vectors = []\n",
    "            for imp_token in k_most_imp_tokenlvl(k, category, max_df=max_df, min_df=min_df):\n",
    "                try:\n",
    "                    imp_tokens_vectors.append(word2vec_model[imp_token])\n",
    "                except:\n",
    "                    imp_tokens_vectors.append(np.zeros(MODEL_DIMENSION))\n",
    "\n",
    "            tknzr = Tokenizer(preserve_case=True)\n",
    "            tweets = [tknzr.tokenize(tweet) for tweet in tweets]\n",
    "\n",
    "            for tweet in tweets:\n",
    "                tweet_vectors = []\n",
    "                for token in tweet:\n",
    "                    try:\n",
    "                        tweet_vectors.append(word2vec_model[token])\n",
    "                    except:\n",
    "                        prefix = find_subtoken(token, word2vec_model, mode='initial')\n",
    "                        suffix = find_subtoken(token, word2vec_model, mode='final')\n",
    "\n",
    "                        if prefix != None and suffix != None:\n",
    "                            tweet_vectors.append(word2vec_model[prefix])\n",
    "                            tweet_vectors.append(word2vec_model[suffix])\n",
    "                        elif prefix != None and suffix == None:\n",
    "                            tweet_vectors.append(word2vec_model[prefix])\n",
    "                        elif prefix == None and suffix != None:\n",
    "                            tweet_vectors.append(word2vec_model[suffix])\n",
    "                        else:\n",
    "                            tweet_vectors.append(np.zeros(MODEL_DIMENSION))\n",
    "\n",
    "                similarity = cosine_similarity(np.asarray(tweet_vectors), np.asarray(imp_tokens_vectors))\n",
    "\n",
    "                feats_max.append(np.amax(similarity, axis=0))\n",
    "                feats_min.append(np.amin(similarity, axis=0))\n",
    "\n",
    "            return np.concatenate((feats_max, feats_min), axis=1)\n",
    "        N_TIMP_TASK1 = 1250     \n",
    "\n",
    "        #X_TIMP_task1_train = pickle.load(open(PICKLE_FOLDER_PATH + \"X_TIMP_task1_train.p\", \"rb\" ))\n",
    "\n",
    "        X_TIMP_task1_train = \\\n",
    "        np.concatenate((get_TIMP_feats(X_train, N_TIMP_TASK1, 'OTHER'),\n",
    "                        get_TIMP_feats(X_train, N_TIMP_TASK1, 'OFFENSE')), axis=1)\n",
    "\n",
    "\n",
    "        X_TIMP_task1_mdp = \\\n",
    "        np.concatenate((get_TIMP_feats(X_test_mdp,  N_TIMP_TASK1, 'OTHER'),\n",
    "                        get_TIMP_feats(X_test_mdp,  N_TIMP_TASK1, 'OFFENSE')), axis=1)\n",
    "        \n",
    "        print('X_TIMP_task1_mdp: ' + str(X_TIMP_task1_mdp.shape))\n",
    "        print('X_TIMP_task1_train: ' + str(X_TIMP_task1_train.shape))\n",
    "        pickle.dump(X_TIMP_task1_train, open(PICKLE_FOLDER_PATH + \"X_TIMP_task1_train.p\", \"wb\" ))\n",
    "\n",
    "    ##### CIMP Features\n",
    "\n",
    "        def k_most_imp_charlvl(k, category, max_df=0.01, min_df=0.0002):    \n",
    "            char_vect  = TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 7), lowercase=False,\n",
    "                                         max_df=max_df, min_df=min_df,\n",
    "                                         preprocessor=Tokenizer(preserve_case=True, join=True).tokenize)\n",
    "\n",
    "            tfidf = char_vect.fit_transform(X_train)\n",
    "\n",
    "            vocab = char_vect.vocabulary_\n",
    "            inv_vocab = {index: word for word, index in vocab.items()}\n",
    "\n",
    "            if category in ['OTHER', 'OFFENSE']:\n",
    "                cat_ids = np.where(y_train_t1 == category)\n",
    "            elif category in ['PROFANITY', 'ABUSE', 'INSULT']:\n",
    "                cat_ids = np.where(y_train_t2 == category)       \n",
    "\n",
    "            most_imp_ids = np.argsort(np.asarray(np.mean(tfidf[cat_ids], axis=0)).flatten())[::-1]\n",
    "\n",
    "            most_imp = []\n",
    "            for index in most_imp_ids:\n",
    "                most_imp.append(inv_vocab[index])\n",
    "\n",
    "            return most_imp[:k]\n",
    "\n",
    "        def get_CIMP_feats(tweets, k, category, max_df=0.01, min_df=0.0002):\n",
    "            feats = np.zeros((len(tweets), k))\n",
    "            for imp_ngram_index, imp_ngram in enumerate(k_most_imp_charlvl(k, category, max_df=max_df, min_df=min_df)):\n",
    "                for tweet_index, tweet in enumerate(tweets):\n",
    "                    if tweet.find(imp_ngram) != -1:\n",
    "                        feats[tweet_index][imp_ngram_index] = 1\n",
    "            return feats\n",
    "\n",
    "        N_CIMP_TASK1 = 3200\n",
    "        N_CIMP_TASK2 = 370\n",
    "        \n",
    "        # X_CIMP_task1_train = pickle.load(open(PICKLE_FOLDER_PATH + \"X_CIMP_task1_train.p\", \"rb\" ))\n",
    "\n",
    "        X_CIMP_task1_train = \\\n",
    "        np.concatenate((get_CIMP_feats(X_train, N_CIMP_TASK1, 'OTHER'),\n",
    "                        get_CIMP_feats(X_train, N_CIMP_TASK1, 'OFFENSE')), axis=1)\n",
    "\n",
    "\n",
    "        X_CIMP_task1_mdp = \\\n",
    "        np.concatenate((get_CIMP_feats(X_test_mdp,  N_CIMP_TASK1, 'OTHER'),\n",
    "                        get_CIMP_feats(X_test_mdp,  N_CIMP_TASK1, 'OFFENSE')), axis=1)\n",
    "        \n",
    "        print('X_CIMP_task1_mdp: ' + str(X_CIMP_task1_mdp.shape))\n",
    "        print('X_CIMP_task1_train: ' + str(X_CIMP_task1_train.shape))\n",
    "        pickle.dump(X_CIMP_task1_train, open(PICKLE_FOLDER_PATH + \"X_CIMP_task1_train.p\", \"wb\" ))\n",
    "        \n",
    "    #### Predictions\n",
    "        _, y1, y2 = get_train_data(TRAIN_FILENAME)\n",
    "        \n",
    "\n",
    "\n",
    "    ## Funktion für das Aufteilen in Train und Test Sample \n",
    "    # -> StratifiedKFold sorgt dafür, dass das prozentuale Verhältnis der Klassen im jeweiligen Sample (Test, Train) gleich ist\n",
    "\n",
    "\n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "        from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "        def get_META_feats(clf, X_train, mdp, y, seeds=[42]):\n",
    "            feats_train = []\n",
    "            for seed in seeds:\n",
    "                skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "                feats_train.append(cross_val_predict(clf, X_train, y=y, method='predict_proba', cv=skf, n_jobs=-1))\n",
    "            feats_train = np.mean(feats_train, axis=0)\n",
    "            print('Länge bzw Anzahl an Features_train: ' + str(len(feats_train)))\n",
    "            print('Classifier: ' + str(clf))\n",
    "            clf.fit(X_train, y)\n",
    "            feats_mdp = clf.predict_proba(mdp)\n",
    "            print('Länge bzw Anzahl an Features_mdp: ' + str(len(feats_mdp)))\n",
    "\n",
    "            return feats_train, feats_mdp\n",
    "\n",
    "    # ## TASK 1 - Base level predictions\n",
    "    # Die drei verschiedenen Classifier (clfs_task1) werden auf die Feature Vectoren (base_feats_task1) angewandt.\n",
    "    # Von einer 10-fold CrossVal wird für den Trainings Feature Satz der Durchschnitt genommen (jeder Spalte).\n",
    "    # Bei den Test-/mdp Daten wird keine Cross Val durchgeführt (keine y Variablen) sondern nur mit jedem Classifier eine prediction anhand der Feature Vektoren gemacht\n",
    "\n",
    "\n",
    "        clfs_task1 = [LogisticRegression(class_weight='balanced', max_iter=200),\n",
    "                      ExtraTreesClassifier(n_estimators=100, criterion='entropy', n_jobs=-1),\n",
    "                      ExtraTreesClassifier(n_estimators=100, criterion='gini', n_jobs=-1)]\n",
    "\n",
    "        base_feats_task1 = [(X_CIMP_task1_train, X_CIMP_task1_mdp),\n",
    "                            (X_TIMP_task1_train, X_TIMP_task1_mdp),\n",
    "                            (X_CNGR_train, X_CNGR_mdp),\n",
    "                            (X_TNGR_train, X_TNGR_mdp),\n",
    "                            (X_EMB_train, X_EMB_mdp)]\n",
    "        X_META_task1_train = []\n",
    "        #X_META_task1_test  = []\n",
    "        X_META_task1_mdp  = []\n",
    "        for X_train, mdp in base_feats_task1:                 # X-train z.B X_CIMP_task1_train, mdp z.B X_CIMP_task1_mdp\n",
    "            for clf in clfs_task1:\n",
    "                feats = get_META_feats(clf, X_train, mdp, y1)\n",
    "                print(str(X_train)+str(clf)+': ' + str(len(feats[0])))\n",
    "                print(str(mdp)+str(clf)+': ' + str(len(feats[1])))                \n",
    "\n",
    "                X_META_task1_train.append(feats[0])           # aus \"get_META_feats: feats_train\n",
    "                X_META_task1_mdp.append(feats[1])             # aus \"get_META_feats: feats_mdp\n",
    "\n",
    "        X_META_task1_train = np.concatenate(X_META_task1_train, axis=1)\n",
    "        X_META_task1_mdp  = np.concatenate(X_META_task1_mdp, axis=1)\n",
    "        print('train: '+str(X_META_task1_train.shape))\n",
    "        print('mdp: '+str(X_META_task1_mdp.shape))\n",
    "\n",
    "        clf_task1 = LogisticRegression(C=0.17, class_weight='balanced', max_iter=1000)\n",
    "        clf_task1.fit(X_META_task1_train, y1) \n",
    "\n",
    "        preds_task1 = clf_task1.predict(X_META_task1_mdp) \n",
    "        \n",
    "        save_df = df_test_rand\n",
    "        save_df['predict'] = preds_task1\n",
    "        pickle.dump(save_df, open(Eval_Path + 'Eval_1.p', \"wb\" ))\n",
    "\n",
    "        #pd.set_option('display.max_colwidth', 0)\n",
    "        #save_df = sample_df[sample_df['Woche'] == week]\n",
    "        #save_df['predict'] = preds_task1\n",
    "        #pickle.dump(save_df, open(PICKLE_FOLDER_PATH + 'Twitter_Sent_Wien_'+week+ '_3.p', \"wb\" ))\n",
    "        #print(\"%s: end labeling\" % (datetime.now().strftime(\"%H:%M:%S\")))\n",
    "        \n",
    "    #else:\n",
    "    #    print(\"Wiederholung: \" + week + \" wurde bereits verwendet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9541, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_META_task1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = df_test_rand\n",
    "save_df['predict'] = preds_task1\n",
    "pickle.dump(save_df, open(Eval_Path + 'Eval_1.p', \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
