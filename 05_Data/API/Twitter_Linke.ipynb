{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lade Daten per Twitter API\n",
    "*Es werden Timeline Daten für jeden aktuellen Bundestags Politiker geladen, der auf Twitter aktiv ist. \n",
    "Die Daten werden anschließend in MongoDB abgelegt, wobei jeder Tweet einem Dokument entspricht. Die Namen der User wurden von den Fraktionsseiten gecrawled.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Verbindung aufsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweepy statt twitter Paket\n",
    "# https://www.earthdatascience.org/courses/earth-analytics-python/using-apis-natural-language-processing-twitter/get-and-use-twitter-data-in-python/\n",
    "\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "\n",
    "# Die folgenden Zugangsaten können bei Twitter Developer abgerufen werden, sobald ein Account erstellt wurde\n",
    "consumer_key = os.getenv('consumer_key')\n",
    "consumer_secret = os.getenv('consumer_secret')\n",
    "access_token_key = os.getenv('access_token_key')\n",
    "access_token_secret = os.getenv('access_token_secret')\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token_key, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Verbindung und speichern in Mongo DB\n",
    "In der Collection Twitter_mdp wird jeder Tweet mit allen Metainformationen als ein Dokument gespeichert. Es werden Tweets zu allen auf Twitter aktiven Politikern einer Fraktion gesammelt. Die entsprechenden Namen wurden von den Bundestagsfraktionsseiten gecrawled.\n",
    "\n",
    "Anfang Juni 2020 wurde zur Qualitätsicherung des Datensatzes außerdem eine manuelle Kontrolle durchgeführt. Dabei fiel auf, dass der Großteil von Abgeordneten einen Twitter Account besitzen, dieser aber nicht auf der Fraktionsseite verlinkt wurde. Dies ist der Fall bei den folgenden Politikern:\n",
    "\n",
    "\"Birke_Bull\", \"joerg_cezanne\", \"SusanneFerschl\", \"SylviaGabelmann\", \"LoetzschMdB\", \"ZaklinNastic\", \"HESommer\", \"jessica_tatti\"\n",
    "\n",
    "Die Tweets aus den Timelines dieser Politiker wurden entsprechend im Juni in den Datensatz aufgenommen.\n",
    "\n",
    "Für die folgenden Namen gab es Auffälligkeiten, weshalb sie nicht enthalten sind (Grund angegeben):\n",
    "* Team_GLoetzsch existiert nicht (mehr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://127.0.0.1:27017/\")\n",
    "\n",
    "db = client['Twitter']\n",
    "# All_Tweets_collection = db['twitter_mdp_ex_date_proj'] # Flache Collection mit weniger Feldern\n",
    "All_Tweets_collection = db['Twitter_mdp_extend']         # Basis in der zunächst alle Tweets gesammelt werden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über den Zeitraum Feb-Aug 2020 wurde der Datensatz zu verschiedenen Zeitpunkten aktualisiert. Dabei ergaben sich folgende Probleme:\n",
    "* die Option \"since\" in $\\texttt{.user_timeline}$ wird ignoriert wenn man gleichtzeitig \"count\" oder \"page\" verwendet\n",
    "* beim laden in die modifizierte Collection Twitter_mp_datetime wurde ein duplicate error geworfen\n",
    "* durch die Arbeit auf zwei Computern muss die Datenbank bei Aktualisierung synchronisiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UllaJelpke\n",
      "1963\n",
      "MatthiasHoehn\n",
      "3073\n",
      "AndrejHunko\n",
      "3240\n",
      "HeikeHaensel\n",
      "3217\n",
      "MdB_Freihold\n",
      "642\n",
      "HaraldWeinberg\n",
      "472\n",
      "Andi_Wagner\n",
      "3211\n",
      "Katrin_Werner\n",
      "2349\n",
      "KirstenTackmann\n",
      "3236\n",
      "FrStraetmanns\n",
      "1795\n",
      "NicoleGohlke\n",
      "3232\n",
      "GregorGysi\n",
      "2240\n",
      "ernst_klaus\n",
      "1295\n",
      "Diether_Dehm\n",
      "3152\n",
      "anked\n",
      "3219\n",
      "FabioDeMasi\n",
      "3232\n",
      "SevimDagdelen\n",
      "3224\n",
      "ch_buchholz\n",
      "3242\n",
      "Michel_Brandt\n",
      "658\n",
      "NordMdb\n",
      "3209\n",
      "Norbert_MdB\n",
      "3214\n",
      "AlexanderSNeu\n",
      "3173\n",
      "Petra_Sitte_MdB\n",
      "3228\n",
      "pascalmeiser\n",
      "3210\n",
      "Conni_Moehring\n",
      "3199\n",
      "thlutze\n",
      "306\n",
      "MdB_Schreiber\n",
      "802\n",
      "berlinliebich\n",
      "3201\n",
      "Amira_M_Ali\n",
      "610\n",
      "b_riexinger\n",
      "3236\n",
      "MartinaRenner\n",
      "3233\n",
      "Ingrid_Remmers\n",
      "795\n",
      "tpflueger\n",
      "569\n",
      "victorperli\n",
      "2006\n",
      "PetraPauMaHe\n",
      "3210\n",
      "NiemaMovassat\n",
      "3230\n",
      "lgbeutin\n",
      "3228\n",
      "MWBirkwald\n",
      "3233\n",
      "DietmarBartsch\n",
      "3227\n",
      "SBarrientosK\n",
      "3232\n",
      "AkbulutGokay\n",
      "2837\n",
      "DorisAchelwilm\n",
      "3213\n",
      "MichaelLeutert\n",
      "3245\n",
      "SabineLeidig\n",
      "3202\n",
      "JuttaKrellmann\n",
      "2782\n",
      "CarenLay\n",
      "3195\n",
      "AchimKesslerMdB\n",
      "2439\n",
      "katjakipping\n",
      "3213\n",
      "LINKEPELLI\n",
      "3203\n",
      "jankortemdb\n",
      "1592\n",
      "voglerk\n",
      "3238\n",
      "SWagenknecht\n",
      "1597\n",
      "Birke_Bull\n",
      "2442\n",
      "joerg_cezanne\n",
      "104\n",
      "SusanneFerschl\n",
      "1176\n",
      "SylviaGabelmann\n",
      "695\n",
      "LoetzschMdB\n",
      "3190\n",
      "ZaklinNastic\n",
      "3122\n",
      "HESommer\n",
      "1985\n",
      "jessica_tatti\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('Namen_Linke.json') as json_file:\n",
    "    Linke = json.load(json_file)\n",
    "    \n",
    "#Linke = Linke[28:29]\n",
    "#print(Linke)\n",
    "\n",
    "for Abgeordneter in Linke:\n",
    "    i = 1\n",
    "    user = Abgeordneter\n",
    "    print(user)\n",
    "    all_tweets = []\n",
    "    while i <= 100 :\n",
    "        tweets_of_page = api.user_timeline(screen_name = user, tweet_mode = \"extended\", count = 200, page = i, include_rts = True)\n",
    "        #print(len(tweets_of_page))\n",
    "        all_tweets = all_tweets + tweets_of_page\n",
    "        i=i+1\n",
    "        if len(tweets_of_page) == 0:\n",
    "            break    # no more tweets from this user\n",
    "            \n",
    "    for tweet in all_tweets:\n",
    "        All_Tweets_collection.insert_one(tweet._json)\n",
    "    print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jessica_tatti\n"
     ]
    }
   ],
   "source": [
    "#with open('/home/lisa/Darmstadt/Master Arbeit/05_Data/Scrapy/Twitter_user/Twitter_user/spiders/Linke_twitter_clean.json') as json_file:\n",
    "with open('Namen_Linke.json') as json_file:\n",
    "    Linke = json.load(json_file)\n",
    "    \n",
    "Linke = Linke[59]\n",
    "print(Linke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste aller Linke Politiker ohne Daten in Twitter_mdp\n",
    "\n",
    "Für manche Politiker findet man keine Daten in Twitter_mdp, wenn man mit dem Screen_name aus der Liste Linke_twitter_clean sucht.\n",
    "\n",
    "Grund: Die Usernamen in der Liste von der Fraktionsseite (_twitter_clean) weichen ab vom tatsächlichen Screen_name\n",
    "\n",
    "-> Twitter API ist NICHT case sensitiv, MongoDB und Python aber schon!\n",
    "\n",
    "=> Option mit RegEx zu suchen (_twitter_Namen) ODER einen Tweet laden und exakten user_screen_name speichern (siehe unten - _twitter_realNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('/home/lisa/Darmstadt/Master Arbeit/05_Data/Scrapy/Twitter_user/Twitter_user/spiders/Linke_twitter_clean.json') as json_file:\n",
    "#     Linke = json.load(json_file)\n",
    "\n",
    "# Linke_Name = Linke\n",
    "# mdp_not_mongodb = []\n",
    "\n",
    "# for name, n in zip(Linke, range(0,len(Linke))):\n",
    "#     count = 0\n",
    "#     #cursor = All_Tweets_collection.find({\"user.screen_name\": {'$regex':name,'$options':'i'}})\n",
    "#     cursor = All_Tweets_collection.find({\"user.screen_name\": name})\n",
    "#     for doc in cursor:\n",
    "#         count=count+1\n",
    "        \n",
    "#     if count == 0:\n",
    "#         print(count)\n",
    "#         print(name)\n",
    "#         #mdp_not_mongodb.append(name)\n",
    "#         Linke_Name[n] = All_Tweets_collection.find_one({\"user.screen_name\": {'$regex': name,'$options':'i'}})['user']['screen_name']\n",
    "   \n",
    "        \n",
    "# print(mdp_not_mongodb)\n",
    "# with open(\"/home/lisa/Darmstadt/Master Arbeit/05_Data/Scrapy/Twitter_user/Twitter_user/spiders/Linke_twitter_Names.json\", \"a\") as write_file:\n",
    "# #with open(\"mdp_not_mongodb_Linke.json\", \"w\") as write_file:\n",
    "#      json.dump(Linke_Name, write_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen der Liste mit den tatsächlichen screen_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('/home/lisa/Darmstadt/Master Arbeit/05_Data/Scrapy/Twitter_user/Twitter_user/spiders/Linke_twitter_clean.json') as json_file:\n",
    "#     Linke= json.load(json_file)\n",
    "    \n",
    "# #Linke = Linke[]\n",
    "# names = []\n",
    "\n",
    "# for Abgeordneter in Linke:\n",
    "#     user = Abgeordneter\n",
    "#     print(user)\n",
    "#     all_tweets = api.user_timeline(screen_name = user, count = 1, include_rts = True)\n",
    "#     for tweet in all_tweets:\n",
    "#         name = tweet.user.screen_name\n",
    "#         names.append(name)\n",
    "        \n",
    "# print(names)\n",
    "\n",
    "# with open (\"Linke_twitter_realNames\", \"w\") as write_file:\n",
    "#     json.dump(names, write_file)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
